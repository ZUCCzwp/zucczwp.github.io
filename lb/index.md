# 负载均衡架构


## HTTP重定向负载均衡
HTTP 重定向负载均衡是一种比较简单的负载均衡技术实现。来自用户的 HTTP 请求到达负
载均衡服务器以后，负载均衡服务器根据某种负载均衡算法计算得到一个应用服务器的地
址，通过 HTTP 状态码 302 重定向响应，将新的 IP 地址发送给用户浏览器，用户浏览器收
到重定向响应以后，重新发送请求到真正的应用服务器，以此来实现负载均衡

HTTP 重定向负载均衡的优点是设计比较简单，但是它的缺点也比较明显，一方面用户完成
一次访问，就需要请求两次数据中心，一次请求负载均衡服务器，一次是请求应用服务器，
请求处理性能会受很大的影响。

另一个问题是因为响应要重定向到真正的应用服务器，所以需要把应用服务器的 IP 地址暴
露给外部用户，这样可能会带来安全性的问题。
## DNS 负载均衡
当用户从浏览器
发起 HTTP 请求的时候，首先要到 DNS 域名服务器进行域名解析，解析得到 IP 地址以
后，用户才能够根据 IP 地址建立 HTTP 连接，访问真正的数据中心的应用服务器，这时候
就可以在 DNS 域名解析的时候进行负载均衡，也就是说，不同的用户进行域名解析的时
候，返回不同的 IP 地址，从而实现负载均衡。

域名解析直接得到应用服务器的 IP 地址，确实会存在安全性问
题。但是大型互联网应用通常并不直接通过 DNS 解析得到应用服务器 IP 地址，而是解析
得到负载均衡服务器的 IP 地址。也就是说，大型网互联网应用需要两次负载均衡，一次通
过 DNS 负载均衡，用户请求访问数据中心负载均衡服务器集群的某台机器，然后这台负载
均衡服务器再进行一次负载均衡，将用户请求分发到应用服务器集群的某台服务器上。通过
这种方式，应用服务器不需要用公网 IP 将自己暴露给外部访问者，避免了安全性问题。

## 反向代理负载均衡
用户请求到达数据中心以后，最先到达的就是反向代理服
务器。反向代理服务器查找本机是否有请求的资源，如果有就直接返回资源数据，如果没
有，就将请求发送给后面的应用服务器继续处理。事实上，发送请求给应用服务器的时候，
就可以进行负载均衡，将不同的用户请求分发到不同的服务器上面去。Nginx 这样的 HTTP
服务器就会同时提供反向代理与负载均衡功能。

作为互联网应用层的一个协议，HTTP 协议相对说来比较重，效率比较低，所以反向代理负
载均衡通常用在小规模的互联网系统上，只有几台或者十几台服务器的规模。

## IP负载均衡
网络层负载均衡。它的主要工作原理是当用户的请求到达负载
均衡服务器以后，负载均衡服务器会对网络层的数据包的 IP 地址进行转换，修改 IP 地址，
将其修改为应用服务器的 IP 地址，然后把数据包重新发送出去，请求数据就会到达应用服
务器。

IP 负载均衡不需要在 HTTP 协议层工作，可以在操作系统内核直接修改 IP 数据包的地址，
因此，效率比应用层的反向代理负载均衡高得多。但是它依然有一个缺陷，不管是请求还是
响应的数据包，都要通过负载均衡服务器进行 IP 地址转换，才能够正确地把请求数据分发
到应用服务器，或者正确地将响应数据包发送到用户端程序。
## 数据链路层负载均衡
负载均衡服务器并不修改数据包的 IP 地址，而是修改数据链路层里的网卡 mac
地址，在数据链路层实现负载均衡。而应用服务器和负载均衡服务器都使用相同的虚拟 IP
地址，这样 IP 路由就不会受到影响，但是网卡会根据自己的 mac 地址，选择负载均衡服
务器发送到自己网卡的数据包，交给对应的应用程序去处理，处理结束以后，当把响应的数
据包发送到网络上的时候，因为 IP 地址没有修改过，所以这个响应会直接到达用户的浏览
器，而不会再经过负载均衡服务器。

链路层负载均衡避免响应数据再经过负载均衡服务器，因而可以承受较大的数据传输压力，
所以，目前大型互联网应用基本都使用链路层负载均衡。
