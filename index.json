[{"categories":["Auth"],"content":"这篇文章展示了如何使用Authentik对接金蝶云星空.","date":"2024-04-17","objectID":"/k3cloud_login/","tags":["Auth","K3Cloud"],"title":"金蝶云星空对接 authentik实现 sso登录","uri":"/k3cloud_login/"},{"categories":["Auth"],"content":"编写 proxy 服务 端口开放为：8888 逻辑： 获取authentik返回的请求头 X-authentik-username获取用户的用户名 对接金蝶第三方登录生成html5跳转链接，并进行302 跳转 username := r.Header.Get(\"X-authentik-username\") req.Username = username l := logic.NewK3cloudLogic(r.Context(), svcCtx) resp, err := l.K3cloud(\u0026req) if err != nil { httpx.ErrorCtx(r.Context(), w, err) } else { w.Header().Set(\"Location\", resp.Message) w.WriteHeader(http.StatusFound) http.RedirectHandler(resp.Message, http.StatusFound) } ... func (l *K3cloudLogic) K3cloud(req *types.Request) (resp *types.Response, err error) { //拼接 userName := req.Username if userName == \"\" { return nil, errors.New(\"invalid param\") } dbId := l.svcCtx.Config.K3Cloud.DbId appId := l.svcCtx.Config.K3Cloud.AppId appSecret := l.svcCtx.Config.K3Cloud.AppSecret timestamp := time.Now().Unix() arr := []string{dbId, userName, appId, appSecret, fmt.Sprintf(\"%d\", timestamp)} sign := GetSignature(arr) // 签名 l.Debugf(\"generate sign param:%+v result:%v\", arr, sign) arg := domain.GenerateCloudSign{ DBID: dbId, Username: userName, AppId: appId, SignedData: sign, Timestamp: fmt.Sprintf(\"%d\", timestamp), LcId: l.svcCtx.Config.K3Cloud.LcId, OriginType: \"SimPas\", EntryRole: \"\", FormId: \"\", FormType: \"\", Pkid: \"\", OtherArgs: \"\", } argJson := arg.SerializeObject() argJsonBase64 := base64.StdEncoding.EncodeToString([]byte(argJson)) html5Url := l.svcCtx.Config.K3Cloud.BaseUrl + argJsonBase64 // html5入口链接 result := types.Response{} result.Message = html5Url l.Debugf(\"generate html5 url result:%v\", html5Url) return \u0026result, nil } func GetSignature(arr []string) string { // 将数组进行排序 sort.Strings(arr) // 将数组拼接成一个字符串 arrString := strings.Join(arr, \"\") // 对拼接后的字符串进行SHA1加密 sha1Hash := sha1.New() sha1Hash.Write([]byte(arrString)) sha1Bytes := sha1Hash.Sum(nil) // 将加密后的字节转换为十六进制字符串 signature := hex.EncodeToString(sha1Bytes) return signature } ","date":"2024-04-17","objectID":"/k3cloud_login/:1:0","tags":["Auth","K3Cloud"],"title":"金蝶云星空对接 authentik实现 sso登录","uri":"/k3cloud_login/"},{"categories":["Auth"],"content":"配置 authentik proxy provider 详见 authentik proxy provider部分 配置proxy的nginx,10.2.192.4:8888/from/authentik地址是编写 proxy服务地址 location / { # Put your proxy_pass to your application here, and all the other statements you'll need proxy_pass http://10.2.192.4:8888/from/authentik; proxy_set_header Host $host; ############################## # authentik-specific config ############################## auth_request /outpost.goauthentik.io/auth/nginx; error_page 401 = @goauthentik_proxy_signin; auth_request_set $auth_cookie $upstream_http_set_cookie; add_header Set-Cookie $auth_cookie; # translate headers from the outposts back to the actual upstream auth_request_set $authentik_username $upstream_http_x_authentik_username; auth_request_set $authentik_groups $upstream_http_x_authentik_groups; auth_request_set $authentik_email $upstream_http_x_authentik_email; auth_request_set $authentik_name $upstream_http_x_authentik_name; auth_request_set $authentik_uid $upstream_http_x_authentik_uid; proxy_set_header X-authentik-username $authentik_username; proxy_set_header X-authentik-groups $authentik_groups; proxy_set_header X-authentik-email $authentik_email; proxy_set_header X-authentik-name $authentik_name; proxy_set_header X-authentik-uid $authentik_uid; } ","date":"2024-04-17","objectID":"/k3cloud_login/:2:0","tags":["Auth","K3Cloud"],"title":"金蝶云星空对接 authentik实现 sso登录","uri":"/k3cloud_login/"},{"categories":["Linux"],"content":"这篇文章展示了基本的Docker常用命令.","date":"2024-04-09","objectID":"/docker/","tags":["Docker","Linux"],"title":"Docker常用命令","uri":"/docker/"},{"categories":["Linux"],"content":"服务相关 ","date":"2024-04-09","objectID":"/docker/:1:0","tags":["Docker","Linux"],"title":"Docker常用命令","uri":"/docker/"},{"categories":["Linux"],"content":"启动 docker 服务 systemctl start docker ","date":"2024-04-09","objectID":"/docker/:1:1","tags":["Docker","Linux"],"title":"Docker常用命令","uri":"/docker/"},{"categories":["Linux"],"content":"停止 docker 服务 systemctl stop docker ","date":"2024-04-09","objectID":"/docker/:1:2","tags":["Docker","Linux"],"title":"Docker常用命令","uri":"/docker/"},{"categories":["Linux"],"content":"重启 docker 服务 systemctl restart docker ","date":"2024-04-09","objectID":"/docker/:1:3","tags":["Docker","Linux"],"title":"Docker常用命令","uri":"/docker/"},{"categories":["Linux"],"content":"查看 docker 服务状态 systemctl status docker ","date":"2024-04-09","objectID":"/docker/:1:4","tags":["Docker","Linux"],"title":"Docker常用命令","uri":"/docker/"},{"categories":["Linux"],"content":"设置开机启动 docker 服务 systemctl enable docker ","date":"2024-04-09","objectID":"/docker/:1:5","tags":["Docker","Linux"],"title":"Docker常用命令","uri":"/docker/"},{"categories":["Linux"],"content":"镜像相关 ","date":"2024-04-09","objectID":"/docker/:2:0","tags":["Docker","Linux"],"title":"Docker常用命令","uri":"/docker/"},{"categories":["Linux"],"content":"搜索镜像 docker search nginx ","date":"2024-04-09","objectID":"/docker/:2:1","tags":["Docker","Linux"],"title":"Docker常用命令","uri":"/docker/"},{"categories":["Linux"],"content":"拉取镜像 docker pull nginx ","date":"2024-04-09","objectID":"/docker/:2:2","tags":["Docker","Linux"],"title":"Docker常用命令","uri":"/docker/"},{"categories":["Linux"],"content":"构建镜像 docker build -t my_image:1.0 . ","date":"2024-04-09","objectID":"/docker/:2:3","tags":["Docker","Linux"],"title":"Docker常用命令","uri":"/docker/"},{"categories":["Linux"],"content":"查看本地镜像 docker images docker images -q//查看本地镜像 id ","date":"2024-04-09","objectID":"/docker/:2:4","tags":["Docker","Linux"],"title":"Docker常用命令","uri":"/docker/"},{"categories":["Linux"],"content":"删除本地镜像 docker rmi mysql:5.7 docker rmi `docker images -q` //全部删除本地镜像 ","date":"2024-04-09","objectID":"/docker/:2:5","tags":["Docker","Linux"],"title":"Docker常用命令","uri":"/docker/"},{"categories":["Linux"],"content":"导出镜像 docker save -o image.tar target_image:tag ","date":"2024-04-09","objectID":"/docker/:2:6","tags":["Docker","Linux"],"title":"Docker常用命令","uri":"/docker/"},{"categories":["Linux"],"content":"导入镜像 docker load -i image.tar ","date":"2024-04-09","objectID":"/docker/:2:7","tags":["Docker","Linux"],"title":"Docker常用命令","uri":"/docker/"},{"categories":["Linux"],"content":"给镜像打标签 docker tag image_id new_image_name:tag ","date":"2024-04-09","objectID":"/docker/:2:8","tags":["Docker","Linux"],"title":"Docker常用命令","uri":"/docker/"},{"categories":["Linux"],"content":"容器相关 ","date":"2024-04-09","objectID":"/docker/:3:0","tags":["Docker","Linux"],"title":"Docker常用命令","uri":"/docker/"},{"categories":["Linux"],"content":"创建容器 docker run -d --name=my_container -p 8080:8080 tomcat:latest ","date":"2024-04-09","objectID":"/docker/:3:1","tags":["Docker","Linux"],"title":"Docker常用命令","uri":"/docker/"},{"categories":["Linux"],"content":"查看容器列表 docker ps docker ps -q //查看正在运行的容器ID列表 ","date":"2024-04-09","objectID":"/docker/:3:2","tags":["Docker","Linux"],"title":"Docker常用命令","uri":"/docker/"},{"categories":["Linux"],"content":"停止容器 docker stop container ","date":"2024-04-09","objectID":"/docker/:3:3","tags":["Docker","Linux"],"title":"Docker常用命令","uri":"/docker/"},{"categories":["Linux"],"content":"启动已停止的容器 docker start my_container ","date":"2024-04-09","objectID":"/docker/:3:4","tags":["Docker","Linux"],"title":"Docker常用命令","uri":"/docker/"},{"categories":["Linux"],"content":"删除容器 docker rm my_container ","date":"2024-04-09","objectID":"/docker/:3:5","tags":["Docker","Linux"],"title":"Docker常用命令","uri":"/docker/"},{"categories":["Linux"],"content":"进入容器 docker exec [OPTIONS] CONTAINER COMMAND [ARG...] 其中，OPTIONS 可以指定一些参数，CONTAINER 是容器的名称或 ID，COMMAND 是要执行的命令，ARG 是命令的参数。 举例： docker exec -it my_container sh -c \"echo Hello World \u0026\u0026 ls -l\" ","date":"2024-04-09","objectID":"/docker/:3:6","tags":["Docker","Linux"],"title":"Docker常用命令","uri":"/docker/"},{"categories":["Linux"],"content":"查看容器信息 docker inspect my_container ","date":"2024-04-09","objectID":"/docker/:3:7","tags":["Docker","Linux"],"title":"Docker常用命令","uri":"/docker/"},{"categories":["Linux"],"content":"数据拷贝 docker cp container_id:/app/html /mnt/ //将容器中 /app/html 目录拷贝到宿主机 /mnt/ 目录中 docker cp /mnt/dist container_id:/app/ //将宿主机 /mnt/dist 目录拷贝到容器的 /app 目录中 ","date":"2024-04-09","objectID":"/docker/:3:8","tags":["Docker","Linux"],"title":"Docker常用命令","uri":"/docker/"},{"categories":["Auth"],"content":"这篇文章展示了如何使用Authentik.","date":"2024-04-08","objectID":"/authentik-use/","tags":["Auth"],"title":"Authentik使用","uri":"/authentik-use/"},{"categories":["Auth"],"content":"Proxy Provider Proxy Provider (process) 代理前哨设置以下用户特定的标头： X-authentik-username当前登录用户的用户名 X-authentik-groups用户所属的组，用竖线分割 X-authentik-email当前登录用户的邮箱地址 X-authentik-name当前登录用户的全名 X-authentik-uid当前登录用户的哈希标识符 应用程序特定的标头 X-authentik-meta-outpost前哨名称 X-authentik-meta-provider提供者名称 X-authentik-meta-appslug X-authentik-meta-version版本 X-Forwarded-Host客户端发送原始 Host标头 附加： 此外，您可以设置additionalHeaders组或用户的属性来设置其他标头： additionalHeaders: X-test-header: test-value ","date":"2024-04-08","objectID":"/authentik-use/:1:0","tags":["Auth"],"title":"Authentik使用","uri":"/authentik-use/"},{"categories":["Auth"],"content":"退出登录 当您在没有有效 cookie 的情况下访问域时，会自动完成登录. 使用单应用程序模式时，导航至app.domain.tld/outpost.goauthentik.io/sign_out. 使用域级模式时，导航到auth.domain.tld/outpost.goauthentik.io/sign_out，其中 auth.domain.tld 是为提供商配置的外部主机。 要注销，请导航至/outpost.goauthentik.io/sign_out。 ","date":"2024-04-08","objectID":"/authentik-use/:1:1","tags":["Auth"],"title":"Authentik使用","uri":"/authentik-use/"},{"categories":["Auth"],"content":"转发认证 Nginx server { listen 443 ssl http2; server_name _; ssl_certificate /etc/ssl/certs/ssl-cert-snakeoil.pem; ssl_certificate_key /etc/ssl/private/ssl-cert-snakeoil.key; proxy_buffers 8 16k; proxy_buffer_size 32k; location / { # proxy_pass http://localhost:5000; # proxy_set_header Host $host; # proxy_set_header ... ############################## # authentik-specific config ############################## auth_request /outpost.goauthentik.io/auth/nginx; error_page 401 = @goauthentik_proxy_signin; auth_request_set $auth_cookie $upstream_http_set_cookie; add_header Set-Cookie $auth_cookie; # translate headers from the outposts back to the actual upstream auth_request_set $authentik_username $upstream_http_x_authentik_username; auth_request_set $authentik_groups $upstream_http_x_authentik_groups; auth_request_set $authentik_email $upstream_http_x_authentik_email; auth_request_set $authentik_name $upstream_http_x_authentik_name; auth_request_set $authentik_uid $upstream_http_x_authentik_uid; proxy_set_header X-authentik-username $authentik_username; proxy_set_header X-authentik-groups $authentik_groups; proxy_set_header X-authentik-email $authentik_email; proxy_set_header X-authentik-name $authentik_name; proxy_set_header X-authentik-uid $authentik_uid; } location /outpost.goauthentik.io { proxy_pass http://outpost.company:9000/outpost.goauthentik.io; # 确保此虚拟服务器的主机与您配置的外部 URL 匹配 proxy_set_header Host $host; proxy_set_header X-Original-URL $scheme://$http_host$request_uri; add_header Set-Cookie $auth_cookie; auth_request_set $auth_cookie $upstream_http_set_cookie; proxy_pass_request_body off; proxy_set_header Content-Length \"\"; } location @goauthentik_proxy_signin { internal; add_header Set-Cookie $auth_cookie; return 302 /outpost.goauthentik.io/start?rd=$request_uri; } } Nginx代理服务器 proxy_buffers 8 16k; proxy_buffer_size 32k; port_in_redirect off; location / { # Put your proxy_pass to your application here proxy_pass $forward_scheme://$server:$port; # Set any other headers your application might need # proxy_set_header Host $host; # proxy_set_header ... ############################## # authentik-specific config ############################## auth_request /outpost.goauthentik.io/auth/nginx; error_page 401 = @goauthentik_proxy_signin; auth_request_set $auth_cookie $upstream_http_set_cookie; add_header Set-Cookie $auth_cookie; # translate headers from the outposts back to the actual upstream auth_request_set $authentik_username $upstream_http_x_authentik_username; auth_request_set $authentik_groups $upstream_http_x_authentik_groups; auth_request_set $authentik_email $upstream_http_x_authentik_email; auth_request_set $authentik_name $upstream_http_x_authentik_name; auth_request_set $authentik_uid $upstream_http_x_authentik_uid; proxy_set_header X-authentik-username $authentik_username; proxy_set_header X-authentik-groups $authentik_groups; proxy_set_header X-authentik-email $authentik_email; proxy_set_header X-authentik-name $authentik_name; proxy_set_header X-authentik-uid $authentik_uid; } location /outpost.goauthentik.io { proxy_pass http://outpost.company:9000/outpost.goauthentik.io; # 确保此虚拟服务器的主机与您配置的外部 URL 匹配 proxy_set_header Host $host; proxy_set_header X-Original-URL $scheme://$http_host$request_uri; add_header Set-Cookie $auth_cookie; auth_request_set $auth_cookie $upstream_http_set_cookie; proxy_pass_request_body off; proxy_set_header Content-Length \"\"; } location @goauthentik_proxy_signin { internal; add_header Set-Cookie $auth_cookie; return 302 /outpost.goauthentik.io/start?rd=$request_uri; } ","date":"2024-04-08","objectID":"/authentik-use/:1:2","tags":["Auth"],"title":"Authentik使用","uri":"/authentik-use/"},{"categories":["Auth"],"content":"Oauth2 Provider ","date":"2024-04-08","objectID":"/authentik-use/:2:0","tags":["Auth"],"title":"Authentik使用","uri":"/authentik-use/"},{"categories":["Auth"],"content":"前期准备 配置 authentik的oauth2 provider Provider Setting Page 重定向URI填写的是 portainer的主页地址 配置 application Application Setting Page 选择新增好的provider ","date":"2024-04-08","objectID":"/authentik-use/:2:1","tags":["Auth"],"title":"Authentik使用","uri":"/authentik-use/"},{"categories":["Auth"],"content":"配置portainer 我们使用 portainer作为演示 安装 portainer 这里我们使用 docker进行安装 docker volume create portainer_data docker run -d -p 9000:9000 --name=portainer --restart=unless-stopped -v /var/run/docker.sock:/var/run/docker.sock -v portainer_data:/data portainer/portainer-ce 登录portainer平台、 在浏览器中访问 http://localhost:9000 来登录 Portainer，首次使用，需要为 admin用户设置密码。 点击设置里的认证模块 Portainer Setting Page 配置对应的配置项 登出 portainer，出现 Login With Oauth Portainer Login Page 点击Login With Oauth，会跳转到 authentik页面进行授权，授权通过后就能登录到 portainer首页 Authentik Login Page Portainer Login Success ","date":"2024-04-08","objectID":"/authentik-use/:2:2","tags":["Auth"],"title":"Authentik使用","uri":"/authentik-use/"},{"categories":["Auth"],"content":"LDAP Provider ","date":"2024-04-08","objectID":"/authentik-use/:3:0","tags":["Auth"],"title":"Authentik使用","uri":"/authentik-use/"},{"categories":["Auth"],"content":"前期准备 新增 ldap flow 配置 authentik的 ldap provider、 application 配置 authentik ","date":"2024-04-08","objectID":"/authentik-use/:3:1","tags":["Auth"],"title":"Authentik使用","uri":"/authentik-use/"},{"categories":["Auth"],"content":"测试 ldapsearch ldapsearch -x -H ldap://ladp_addr:389 -D 'cn=akadmin,ou=users,dc=ldap,dc=goauthentik,dc=io' -b 'ou=users,dc=ldap,dc=goauthentik,dc=io' -w 'xxx@123' \"cn=akadmin\" jumpserver 我们使用 jumpserver作为演示ldap登录 注意 安装 jumpserver,详见docker安装 jumpserver Jumpserver ldap setting Page 配置完之后就能用 authentik用户登录 jumpserver了 ","date":"2024-04-08","objectID":"/authentik-use/:3:2","tags":["Auth"],"title":"Authentik使用","uri":"/authentik-use/"},{"categories":["DB"],"content":"这篇文章展示了基本的Postgresql常用命令.","date":"2024-04-07","objectID":"/postgresql/","tags":["DB"],"title":"Postgresql常用命令","uri":"/postgresql/"},{"categories":["DB"],"content":"查看 pg版本 psql --version ","date":"2024-04-07","objectID":"/postgresql/:0:1","tags":["DB"],"title":"Postgresql常用命令","uri":"/postgresql/"},{"categories":["DB"],"content":"获取当前db中所有的表信息 select * from pg_tables; //获取名为 public的 schema的所有表 select tablename from pg_tables where schemaname='public' ","date":"2024-04-07","objectID":"/postgresql/:0:2","tags":["DB"],"title":"Postgresql常用命令","uri":"/postgresql/"},{"categories":["DB"],"content":"获取某个表结构信息 \\d authentik_core_user; ","date":"2024-04-07","objectID":"/postgresql/:0:3","tags":["DB"],"title":"Postgresql常用命令","uri":"/postgresql/"},{"categories":["DB"],"content":"获取某个表数据 SELECT * FROM authentik_core_user; ","date":"2024-04-07","objectID":"/postgresql/:0:4","tags":["DB"],"title":"Postgresql常用命令","uri":"/postgresql/"},{"categories":["DB"],"content":"外网不能访问数据库 ::: 1、修改postgresql.conf文件::: 在安装目录下data/postgresql.confi文件中将listen address改为* listen_addresses = '*' ::: 2、修改pg_hba.conf文件::: 在data/pg_hba.conf中设置 host all all 127.0.0.1/32 md5 host all all 0.0.0.0/0 md5 ::: 3、重启 postgres服务::: systemctl restart postgresql ","date":"2024-04-07","objectID":"/postgresql/:0:5","tags":["DB"],"title":"Postgresql常用命令","uri":"/postgresql/"},{"categories":["DB"],"content":"新建数据库 CREATE DATABASE dbname; ","date":"2024-04-07","objectID":"/postgresql/:0:6","tags":["DB"],"title":"Postgresql常用命令","uri":"/postgresql/"},{"categories":["Auth"],"content":"这篇文章展示了authentik安装说明.","date":"2024-04-02","objectID":"/authentik-deploy/","tags":["Auth"],"title":"Authentik安装","uri":"/authentik-deploy/"},{"categories":["Auth"],"content":"Docker安装 MacOs 下载 docker composer文件 curl -O https://goauthentik.io/docker-compose.yml 生成 password和 secret key到.env文件 echo \"PG_PASS=$(openssl rand -base64 36)\" \u003e\u003e .env echo \"AUTHENTIK_SECRET_KEY=$(openssl rand -base64 36)\" \u003e\u003e .env 如果只要开启错误日志,运行 echo \"AUTHENTIK_ERROR_REPORTING__ENABLED=true\" \u003e\u003e .env 邮件配置（可选不推荐） # SMTP Host Emails are sent to AUTHENTIK_EMAIL__HOST=localhost AUTHENTIK_EMAIL__PORT=25 # Optionally authenticate (don't add quotation marks to your password) AUTHENTIK_EMAIL__USERNAME= AUTHENTIK_EMAIL__PASSWORD= # Use StartTLS AUTHENTIK_EMAIL__USE_TLS=false # Use SSL AUTHENTIK_EMAIL__USE_SSL=false AUTHENTIK_EMAIL__TIMEOUT=10 # Email address authentik will send from, should have a correct @domain AUTHENTIK_EMAIL__FROM=authentik@localhost 配置端口号 COMPOSE_PORT_HTTP=80 COMPOSE_PORT_HTTPS=443 开启 docker compose pull docker compose up -d 初始化配置 http://\u003cyour server's IP or hostname\u003e/if/flow/initial-setup/ ","date":"2024-04-02","objectID":"/authentik-deploy/:1:0","tags":["Auth"],"title":"Authentik安装","uri":"/authentik-deploy/"},{"categories":["Auth"],"content":"二进制安装 确定 linux系统的架构 uname -m 如果显示x86_64则是 amd架构 不是则是 arm,也可通过 arch命令得到 2. 前期准备 安装依赖 安装 lib库 sudo yum update -y \u0026\u0026 sudo yum upgrade -y sudo yum install -y curl wget git gcc gcc-c++ sqlite-devel readline-devel ncurses-devel openssl tk-devel gdbm-d evel db4-devel xz-devel make glibc-devel bzip2-devel pkgconfig libffi-devel libpcap-devel zlib-devel xmlsec1 xmlsec1-openssl libmaxminddb postgresql-devel 确定 devel库是否开启 安装 python(要求版本 v3.12+) wget https://www.python.org/ftp/python/3.12.2/Python-3.12.2.tgz tar xzf Python-3.12.2.tgz cd Python-3.12.2 ./configure --enable-optimizations sudo make altinstall rm -rf Python-3.12.2.tgz Python-3.12.2 安装 node(要求版本 v18+) wget https://nodejs.org/dist/latest-v21.x/node-v21.7.1-linux-x64.tar.xz tar xf node-v21.7.1-linux-x64.tar.xz 配置环境变量 安装 go(要求 v1.22+) wget https://golang.org/dl/go1.22.1.linux-amd64.tar.gz sudo tar -C /usr/local -xzf go1.22.1.linux-amd64.tar.gz rm -rf go1.22.1.linux-amd64.tar.gz vim ~/.profile export GOROOT=/usr/local/go export PATH=$PATH:$GOROOT/bin source ~/.profile 安装 pip curl https://bootstrap.pypa.io/get-pip.py -o get-pip.py python get-pip.py rm -rf get-pip.py 安装 py virtualenv pip install virtualenv black ruff codespell bandit poetry pycparser psycopg2 xmlsec1 无网模式需要设置pypi代理 安装 golangci-lint ","date":"2024-04-02","objectID":"/authentik-deploy/:2:0","tags":["Auth"],"title":"Authentik安装","uri":"/authentik-deploy/"},{"categories":["Auth"],"content":"下载https://github.com/golangci/golangci-lint/releases对应 rpm sudo rpm -ivh golangci-lint-1.57.2-linux-386.rpm 安装 website、 web和 python依赖 cd /opt/authentik make install 安装 postgreSql ","date":"2024-04-02","objectID":"/authentik-deploy/:2:1","tags":["Auth"],"title":"Authentik安装","uri":"/authentik-deploy/"},{"categories":["Auth"],"content":"下载路径：https://www.postgresql.org/ftp/source/v16.2/ tar -zxvf postgresql-16.2.tar.gz cd postgresql-16.2 ./configure make \u0026 make install 安装 redis wget http://download.redis.io/releases/redis-4.0.8.tar.gz tar xzvf redis-4.0.8.tar.gz cd redis-4.0.8 make cd src make install PREFIX=/usr/local/redis cd ../ mkdir /usr/local/redis/etc mv redis.conf /usr/local/redis/etc vi /usr/local/redis/etc/redis.conf //将daemonize no改成daemonize yes vi /etc/rc.local //在里面添加内容：/usr/local/redis/bin/redis-server /usr/local/redis/etc/redis.conf /usr/local/redis/bin/redis-server /usr/local/redis/etc/redis.conf cp /usr/local/redis/bin/redis-server /usr/local/bin/ cp /usr/local/redis/bin/redis-cli /usr/local/bin/ 设置环境变量PATH: export PATH=\"/home/admin/opt/authentik/.venv/bin\":$PATH export PATH=\"/home/admin/opt/authentik/lifecycle\":$PATH 启动 authentik服务 ak命令为 lifecycle目录下的可执行文件 ak server ak worker ","date":"2024-04-02","objectID":"/authentik-deploy/:2:2","tags":["Auth"],"title":"Authentik安装","uri":"/authentik-deploy/"},{"categories":["Auth"],"content":"使用 初始化管理员账号密码 打开初始化页面 https://{{your host}}/if/flow/initial-setup/，设置邮箱密码 访问管理后台 打开管理后台 https://{{your host}}/if/admin/#/administration/overview ","date":"2024-04-02","objectID":"/authentik-deploy/:3:0","tags":["Auth"],"title":"Authentik安装","uri":"/authentik-deploy/"},{"categories":["Linux"],"content":"这篇文章展示了基本的Kubectl常用命令.","date":"2024-04-01","objectID":"/kubectl/","tags":["Linux","K8s"],"title":"Kubectl常用命令","uri":"/kubectl/"},{"categories":["Linux"],"content":"配置及上下文 view kubectl config view # 显示合并后的 kubeconfig 配置 current-context kubectl config current-context # 显示当前的上下文 ","date":"2024-04-01","objectID":"/kubectl/:0:1","tags":["Linux","K8s"],"title":"Kubectl常用命令","uri":"/kubectl/"},{"categories":["Linux"],"content":"创建对象 kubectl create -f ./my-manifest.yaml # 创建资源 kubectl create -f https://git.io/vPieo # 使用 url 来创建资源 ","date":"2024-04-01","objectID":"/kubectl/:0:2","tags":["Linux","K8s"],"title":"Kubectl常用命令","uri":"/kubectl/"},{"categories":["Linux"],"content":"显示和查找资源 kubectl get services # 创建资源 kubectl get pods -o wide -n namespace # 列出所有 pod 并显示详细信息 kubectl create -f https://git.io/vPieo # 使用 url 来创建资源 ","date":"2024-04-01","objectID":"/kubectl/:0:3","tags":["Linux","K8s"],"title":"Kubectl常用命令","uri":"/kubectl/"},{"categories":["Linux"],"content":"scale资源 kubectl scale --replicas=3 rs/foo ","date":"2024-04-01","objectID":"/kubectl/:0:4","tags":["Linux","K8s"],"title":"Kubectl常用命令","uri":"/kubectl/"},{"categories":["Linux"],"content":"删除资源 kubectl delete pods,services -l name=myLabel ","date":"2024-04-01","objectID":"/kubectl/:0:5","tags":["Linux","K8s"],"title":"Kubectl常用命令","uri":"/kubectl/"},{"categories":["Linux"],"content":"这篇文章展示了基本的Linux常用命令.","date":"2024-03-19","objectID":"/command/","tags":["Linux"],"title":"Linux常用命令","uri":"/command/"},{"categories":["Linux"],"content":"删除多行 1.首先要显示对应的行数 :set nu 2.Esc退出 190,6233d 即[190 , 6233]都删除掉 ","date":"2024-03-19","objectID":"/command/:0:1","tags":["Linux"],"title":"Linux常用命令","uri":"/command/"},{"categories":["Linux"],"content":"清空文件 \u003e log.txt ","date":"2024-03-19","objectID":"/command/:0:2","tags":["Linux"],"title":"Linux常用命令","uri":"/command/"},{"categories":["Linux"],"content":"显示发行版本信息 lsb_release -v 显示版本信息。 -i 显示发行版的id。 -d 显示该发行版的描述信息。 -r 显示当前系统是发行版的具体版本号。 -c 发行版代号。 -a 显示上面的所有信息。 -h 显示帮助信息。 ","date":"2024-03-19","objectID":"/command/:0:3","tags":["Linux"],"title":"Linux常用命令","uri":"/command/"},{"categories":["Linux"],"content":"查看文件时间 Stat stat install.log Ls modification time（mtime，修改时间）：当该文件的“内容数据”更改时，就会更新这个时间。内容数据指的是文件的内容，而不是文件的属性。 status time（ctime，状态时间）：当该文件的”状态（status）”改变时，就会更新这个时间，举例来说，更改了权限与属性，就会更新这个时间。 access time（atime，存取时间）：当“取用文件内容”时，就会更新这个读取时间。举例来说，使用cat去读取 ~/.bashrc，就会更新atime了。 ls -l --time=ctime install.log ","date":"2024-03-19","objectID":"/command/:0:4","tags":["Linux"],"title":"Linux常用命令","uri":"/command/"},{"categories":["Linux"],"content":"修改文件时间 Touch 同时修改文件的修改时间和访问时间 touch -d \"2010-05-31 08:10:30\" install.log 只修改文件的修改时间 touch -m -d \"2010-05-31 08:10:30\" install.log 只修改文件的访问时间 touch -a -d \"2010-05-31 08:10:30\" install.log ","date":"2024-03-19","objectID":"/command/:0:5","tags":["Linux"],"title":"Linux常用命令","uri":"/command/"},{"categories":["Linux"],"content":"开启 devel库 Linux vim /etc/yum.repos.d/rocky-devel.repo //确认是否开启 yum grouplist yum group install '开发工具' Ubuntu/Debian sudo apt update sudo apt install build-essential ","date":"2024-03-19","objectID":"/command/:0:6","tags":["Linux"],"title":"Linux常用命令","uri":"/command/"},{"categories":["Linux"],"content":"查看进程 lsof -i:端口号 netstat -nap | grep 端口号 ","date":"2024-03-19","objectID":"/command/:0:7","tags":["Linux"],"title":"Linux常用命令","uri":"/command/"},{"categories":["Linux"],"content":"查看磁盘使用情况 du -f ","date":"2024-03-19","objectID":"/command/:0:8","tags":["Linux"],"title":"Linux常用命令","uri":"/command/"},{"categories":["Linux"],"content":"抓包 tcpdump -D //列出可用的网卡列表 tcpdump -i eth0 //设置抓取的网卡名 tcpdump -i eth0 -w debug.cap //把捕获的包数据写入到文件中 tcpdump -A //以 ASCII 码方式显示每一个数据包 tcpdump -c 10 //设置抓取到多少个包后退出 tcpdump -w data.pcap port 80//将包数据写入文件 指定监听端口为 80 ","date":"2024-03-19","objectID":"/command/:0:9","tags":["Linux"],"title":"Linux常用命令","uri":"/command/"},{"categories":["Seo"],"content":"这篇文章展示了网站优化之 sitemap网站地图写法.","date":"2024-03-18","objectID":"/optimize_web/","tags":[" Seo"],"title":"网站优化","uri":"/optimize_web/"},{"categories":["Seo"],"content":"定义 网站地图（sitemap.xml）是一个网站的概览。搜索引擎在此文件中得到网站上存在的可抓取的网页，提交sitemap有利于搜索引擎的收录。 网站地图是一个网站的缩影，包含网站的内容地址，是根据网站的结构、框架、内容，生成的导航文件。网站地图分为三种文件格式：xml格式、html格式以及txt格式。xml格式和txt格式一般用于搜索引擎，为搜索引擎蜘蛛程序提供便利的入口到你的网站所有网页；html格式网站地图可以作为一个网页展示给访客，方便用户查看网站内容。 ","date":"2024-03-18","objectID":"/optimize_web/:0:1","tags":[" Seo"],"title":"网站优化","uri":"/optimize_web/"},{"categories":["Seo"],"content":"生成方法 Sitemap 0.90 是依据创意公用授权-相同方式共享的条款提供的，并被广泛采用，受 Google、Yahoo! 和 Microsoft 在内的众多厂商的支持。[网址](https://www. sitemaps.org/zh_CN/faq.html) \u003c?xml version=\"1.0\" encoding=\"UTF-8\"?\u003e \u003curlset xmlns=\"http://www.sitemaps.org/schemas/sitemap/0.9\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://www.sitemaps.org/schemas/sitemap/0.9 http://www.sitemaps.org/schemas/sitemap/0.9/sitemap.xsd\"\u003e \u003curl\u003e \u003cloc\u003ehttp://www.zwp.com/\u003c/loc\u003e \u003cchangefreq\u003edaily\u003c/changefreq\u003e \u003c/url\u003e \u003curl\u003e \u003cloc\u003ehttp://www.zwp.com/wyblog?catid=43\u003c/loc\u003e \u003cchangefreq\u003edaily\u003c/changefreq\u003e \u003c/url\u003e \u003curl\u003e \u003cloc\u003ehttp://www.zwp.com/wyblog/?catid=167\u003c/loc\u003e \u003cchangefreq\u003edaily\u003c/changefreq\u003e \u003c/url\u003e \u003curl\u003e \u003cloc\u003ehttp://www.zwp.com/wyblog/?catid=170\u003c/loc\u003e \u003cchangefreq\u003edaily\u003c/changefreq\u003e \u003c/url\u003e \u003c/urlset\u003e ","date":"2024-03-18","objectID":"/optimize_web/:0:2","tags":[" Seo"],"title":"网站优化","uri":"/optimize_web/"},{"categories":["Seo"],"content":"提交步骤 生成网站地图： 网页版：http://www.xml-sitemaps.com/ 客户端：http://cn.sitemapx.com/ change frequency:指的是频率，地图的自动更新频率，默认每天(daily); last modification:是网站地图最后修改时间，默认使用服务器的响应(Use server’s response); priority:权重-可自动计算。 点击start开始生产。自动跳转到生成页面，稍等一段时间便可生成（时间和网站内容多少有关）。 它提供多种格式的网站地图文件下载(xml、xml.gz、ror.xml、html等)，看你所提交的搜索引擎需要哪种格式的地图文件，就下载哪一个，或者直接打包全下载。 下载生成的地图文件sitemap.xml并上传至网站根目录 到站长平台提交网站地图。 注意 各搜索引擎推荐网站地图格式： Google：建议使用xml格式的网站地图 Google提交地址 Yahoo： 建议使用Txt格式的网站地图 Yahoo提交地址 Baidu：建议使用robots.txt提交html格式的网站地图 Baidu提交地址 在robots.txt爬虫协议中定义（Allow: /sitemap.hxml）robots.txt文档是表式允许蜘蛛网访问网站地图。爬虫协议写法参见：网站优化之robots.txt爬虫协议的写法。 ","date":"2024-03-18","objectID":"/optimize_web/:0:3","tags":[" Seo"],"title":"网站优化","uri":"/optimize_web/"},{"categories":["Redis"],"content":"这篇文章展示了Go-redis高级用法.","date":"2024-03-17","objectID":"/go-redis/","tags":["Redis"],"title":"Go-redis高级用法","uri":"/go-redis/"},{"categories":["Redis"],"content":"开启对 Cluster中 Slave Node的访问 在一个负载比较高的Redis Cluster中，如果允许对slave节点进行读操作将极大的提高集群的吞吐能力。 开启对Slave 节点的访问，受以下3个参数的影响 type ClusterOptions struct { ReadOnly bool RouteByLatency bool RouteRandomly bool ... } go-redis 选择节点的逻辑如下 func (c *ClusterClient) cmdSlotAndNode(cmd Cmder) (int, *clusterNode, error) { state, err := c.state.Get() if err != nil { return 0, nil, err } cmdInfo := c.cmdInfo(cmd.Name()) slot := cmdSlot(cmd, cmdFirstKeyPos(cmd, cmdInfo)) if c.opt.ReadOnly \u0026\u0026 cmdInfo != nil \u0026\u0026 cmdInfo.ReadOnly { if c.opt.RouteByLatency { node, err := state.slotClosestNode(slot) return slot, node, err } if c.opt.RouteRandomly { node := state.slotRandomNode(slot) return slot, node, nil } node, err := state.slotSlaveNode(slot) return slot, node, err } node, err := state.slotMasterNode(slot) return slot, node, err } 如果ReadOnly = true，只选择Slave Node 如果ReadOnly = true 且 RouteByLatency = true 将从slot对应的Master Node 和 Slave Node选择，选择策略为: 选择PING 延迟最低的节点 如果ReadOnly = true 且 RouteRandomly = true 将从slot对应的Master Node 和 Slave Node选择，选择策略为:随机选择 ","date":"2024-03-17","objectID":"/go-redis/:0:1","tags":["Redis"],"title":"Go-redis高级用法","uri":"/go-redis/"},{"categories":["Redis"],"content":"在集群模式下使用pipeline功能 Redis的pipeline功能的原理是 Client通过一次性将多条redis命令发往Redis Server，减少了每条命令分别传输的IO开销。同时减少了系统调用的次数，因此提升了整体的吞吐能力。 我们在主-从模式的Redis中，pipeline功能应该用的很多，但是Cluster模式下，估计还没有几个人用过。 我们知道 redis cluster 默认分配了 16384 个slot，当我们set一个key 时，会用CRC16算法来取模得到所属的slot，然后将这个key 分到哈希槽区间的节点上，具体算法就是：CRC16(key) % 16384。如果我们使用pipeline功能，一个批次中包含的多条命令，每条命令涉及的key可能属于不同的slot go-redis 为了解决这个问题, 分为3步 源码可以阅读 defaultProcessPipeline 将计算command 所属的slot, 根据slot选择合适的Cluster Node 将同一个Cluster Node 的所有command，放在一个批次中发送（并发操作） 接收结果 注意 注意：这里go-redis 为了处理简单，每个command 只能涉及一个key, 否则你可能会收到如下错误err CROSSSLOT Keys in request don't hash to the same slot go-redis不支持类似 MGET 命令的用法 package main import ( \"github.com/go-redis/redis\" \"fmt\" ) func main() { client := redis.NewClusterClient(\u0026redis.ClusterOptions{ Addrs: []string{\"192.168.120.110:6380\", \"192.168.120.111:6380\"}, ReadOnly: true, RouteRandomly: true, }) pipe := client.Pipeline() pipe.HGetAll(\"1371648200\") pipe.HGetAll(\"1371648300\") pipe.HGetAll(\"1371648400\") cmders, err := pipe.Exec() if err != nil { fmt.Println(\"err\", err) } for _, cmder := range cmders { cmd := cmder.(*redis.StringStringMapCmd) strMap, err := cmd.Result() if err != nil { fmt.Println(\"err\", err) } fmt.Println(\"strMap\", strMap) } } ","date":"2024-03-17","objectID":"/go-redis/:0:2","tags":["Redis"],"title":"Go-redis高级用法","uri":"/go-redis/"},{"categories":["Nginx"],"content":"这篇文章展示了 Nginx Error Page配置.","date":"2024-03-02","objectID":"/nginx_config/","tags":["Nginx"],"title":"Nginx Error Page配置","uri":"/nginx_config/"},{"categories":["Nginx"],"content":"语法 error_page code [ code... ] [ = | =answer-code ] uri |@named_location ","date":"2024-03-02","objectID":"/nginx_config/:0:1","tags":["Nginx"],"title":"Nginx Error Page配置","uri":"/nginx_config/"},{"categories":["Nginx"],"content":"示例 作用是当发生错误的时候能够显示一个预定义的uri error_page 502 503 /50x.html; location = /50x.html { root /usr/share/nginx/html; } 这样实际上产生了一个内部跳转(internal redirect)，当访问出现502、503的时候就能返回50x.html中的内容，这里需要注意是否可以找到50x.html页面，所以加了个location保证找到你自定义的50x页面。 同时我们也可以自己定义这种情况下的返回状态吗，比如： error_page 502 503 =200 /50x.html; location = /50x.html { root /usr/share/nginx/html; } 这样用户访问产生502 、503的时候给用户的返回状态是200，内容是50x.html。 当error_page后面跟的不是一个静态的内容的话，比如是由proxyed server或者FastCGI/uwsgi/SCGI server处理的话，server返回的状态(200, 302, 401 或者 404）也能返回给用户。 error_page 404 = /404.php; location ~ \\.php$ { fastcgi_pass 127.0.0.1:9000; fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name; include fastcgi_params; } 也可以设置一个named location，然后在里边做对应的处理。 error_page 500 502 503 504 @jump_to_error; location @jump_to_error { proxy_pass http://backend; } 同时也能够通过使客户端进行302、301等重定向的方式处理错误页面，默认状态码为302。 error_page 403 http://example.com/forbidden.html; error_page 404 =301 http://example.com/notfound.html; 同时error_page在一次请求中只能响应一次，对应的nginx有另外一个配置可以控制这个选项：recursive_error_pages 默认为false，作用是控制error_page能否在一次请求中触发多次。 ","date":"2024-03-02","objectID":"/nginx_config/:0:2","tags":["Nginx"],"title":"Nginx Error Page配置","uri":"/nginx_config/"},{"categories":["Nginx"],"content":"Nginx 自定义404错误页面配置中有无等号的区别 error_page 404 /404.html 可显示自定义404页面内容，正常返回404状态码。 error_page 404 = /404.html 可显示自定义404页面内容，但返回200状态码。 error_page 404 /404.php 如果是动态404错误页面，包含 header 代码（例如301跳转），将无法正常执行。正常返回404代码。 error_page 404 = /404.php 如果是动态404错误页面，包含 header 代码（例如301跳转），加等号配置可以正常执行，返回php中定义的状态码。但如果php中定义返回404状态码，404状态码可以正常返回，但无法显示自定义页面内容（出现系统默认404页面），这种情况可以考虑用410代码替代（ header(“HTTP/1.1 410 Gone”); 正常返回410状态码，且可正常显示自定义内容）。 注意 由于在nginx配置中，设置了limit_req的流量限制，导致许多请求返回503错误代码，在限流的条件下，为提高用户体验，希望返回正常Code 200，且返回操作频繁的信息： location /test { ... limit_req zone=zone_ip_rm burst=1 nodelay; error_page 503 =200 /dealwith_503?callback=$arg_callback; } location /dealwith_503{ set $ret_body '{\"code\": \"V00006\",\"msg\": \"操作太频繁了，请坐下来喝杯茶。\"}'; if ( $arg_callback != \"\" ) { return 200 'try{$arg_callback($ret_body)}catch(e){}'; } return 200 $ret_body; } ","date":"2024-03-02","objectID":"/nginx_config/:0:3","tags":["Nginx"],"title":"Nginx Error Page配置","uri":"/nginx_config/"},{"categories":["Nginx"],"content":"这篇文章展示了 Nginx配置.","date":"2024-03-02","objectID":"/nginx_error_page/","tags":["Nginx"],"title":"Nginx配置","uri":"/nginx_error_page/"},{"categories":["Nginx"],"content":"location 语法 规则 location [=|~|~*|^~] /uri/ { ····· } = 开头表示精确匹配 ^~ 开头表示uri以某个常规字符串开头，理解为匹配 url路径即可。nginx不对url做编码，因此请求为/static/20%/aa，可以被规则^~ /static/ /aa匹配到（注意是空格） ~ 开头表示区分大小写的正则匹配 ~* 开头表示不区分大小写的正则匹配 !~ 区分大小写不匹配的正则 !~* 不区分大小写不匹配的正则 / 通用匹配，任何请求都会匹配到 匹配顺序： 首先匹配 “=\"，其次匹配 “^~”, 其次是按文件中顺序的正则匹配，最后是交给 “/” 通用匹配。 当有匹配成功时候，停止匹配，按当前匹配规则处理请求 ","date":"2024-03-02","objectID":"/nginx_error_page/:0:1","tags":["Nginx"],"title":"Nginx配置","uri":"/nginx_error_page/"},{"categories":["Nginx"],"content":"rewrite 语法 规则： last – 基本上都用这个 Flag break – 中止 Rewirte，不在继续匹配 redirect – 返回临时重定向的HTTP状态302 permanent – 返回永久重定向的HTTP状态301 可用来判断的表达式 -f 和 !-f 用来判断是否存在文件 -d 和 !-d 用来判断是否存在目录 -e 和 !-e 用来判断是否存在文件或目录 -x 和 !-x 用来判断文件是否可执行 可用来判断的全局变量 例：http://localhost:88/test1/test2/test.php $host：localhost $server_port：88 $request_uri：http://localhost:88/test1/test2/test.php $document_uri：/test1/test2/test.php $document_root：D:\\nginx/html $request_filename：D:\\nginx/html/test1/test2/test.php ","date":"2024-03-02","objectID":"/nginx_error_page/:0:2","tags":["Nginx"],"title":"Nginx配置","uri":"/nginx_error_page/"},{"categories":["Nginx"],"content":"redirect 语法 server { listen 80; server_name start.igrow.cn; index index.html index.php; root html; if ($http_host !~ “^star\\.igrow\\.cn$\u0026quot { rewrite ^(.*) http://star.igrow.cn$1 redirect; } } ","date":"2024-03-02","objectID":"/nginx_error_page/:0:3","tags":["Nginx"],"title":"Nginx配置","uri":"/nginx_error_page/"},{"categories":["Nginx"],"content":"防盗链语法 location ~* \\.(gif|jpg|swf)$ { valid_referers none blocked start.igrow.cn sta.igrow.cn; if ($invalid_referer) { rewrite ^/ http://$host/logo.png; } } ","date":"2024-03-02","objectID":"/nginx_error_page/:0:4","tags":["Nginx"],"title":"Nginx配置","uri":"/nginx_error_page/"},{"categories":["Nginx"],"content":"根据文件类型设置过期时间 location ~* \\.(js|css|jpg|jpeg|gif|png|swf)$ { if (-f $request_filename) { expires 1h; break; } } ","date":"2024-03-02","objectID":"/nginx_error_page/:0:5","tags":["Nginx"],"title":"Nginx配置","uri":"/nginx_error_page/"},{"categories":["Nginx"],"content":"禁止访问某个目录 location ~* \\.(txt|doc)${ root /data/www/wwwroot/linuxtone/test; deny all; } ","date":"2024-03-02","objectID":"/nginx_error_page/:0:6","tags":["Nginx"],"title":"Nginx配置","uri":"/nginx_error_page/"},{"categories":["Mysql"],"content":"这篇文章展示了Mysql用法.","date":"2024-02-17","objectID":"/mysql/","tags":["Mysql"],"title":"Mysql用法","uri":"/mysql/"},{"categories":["Mysql"],"content":"导出 mysqldump -uroot -pdbpasswd dbname test1 test2 test3\u003edb.sql ","date":"2024-02-17","objectID":"/mysql/:0:1","tags":["Mysql"],"title":"Mysql用法","uri":"/mysql/"},{"categories":["Mysql"],"content":"合并 表达式 COALESCE是一个函数， (expression_1, expression_2, …,expression_n)依次参考各参数表达式，遇到非null值即停止并返回该值。如果所有的表达式都是空值，最终将返回一个空值。使用COALESCE在于大部分包含空值的表达式最终将返回空值。 示例： select coalesce(success_cnt, 1) from tableA 当success_cnt 为null值的时候，将返回1，否则将返回success_cnt的真实值 select coalesce(success_cnt,period,1) from tableA 当success_cnt不为null，那么无论period是否为null，都将返回success_cnt的真实值（因为success_cnt是第一个参数），当success_cnt为null，而period不为null的时候，返回period的真实值。只有当success_cnt和period均为null的时候，将返回1。 ","date":"2024-02-17","objectID":"/mysql/:0:2","tags":["Mysql"],"title":"Mysql用法","uri":"/mysql/"},{"categories":["Mysql"],"content":"强制索引 force index select customer,count(1) c from upv_1 force index(idx_created) where created between \"2015-07-06\" and \"2015-07-07\" group by customer having c \u003e 15 order by c desc ","date":"2024-02-17","objectID":"/mysql/:0:3","tags":["Mysql"],"title":"Mysql用法","uri":"/mysql/"},{"categories":["Mysql"],"content":"重建索引 alter table T engine=InnoDB。 ","date":"2024-02-17","objectID":"/mysql/:0:4","tags":["Mysql"],"title":"Mysql用法","uri":"/mysql/"},{"categories":["Mysql"],"content":"排序 过滤 过滤 is_buy=0的值 SELECT * FROM mall.m_store_sort ORDER BY is_buy=0 ,is_buy ASC ","date":"2024-02-17","objectID":"/mysql/:0:5","tags":["Mysql"],"title":"Mysql用法","uri":"/mysql/"},{"categories":["Mysql"],"content":"索引策略 独立的列 索引列不能是表达式的一部分，也不能是函数的参数 前缀索引和索引选择性 索引的选择性： 不重复的索引值和数据表的记录总数的比值，索引的选择性越高查询效率越高。 对于BLOB/TEXT或者很长的VARCHAR类型的列，必须使用前缀索引。因为Mysql不允许索引这些列的完整的长度 诀窍在于要选择足够长的前缀以保证较高的选择性，同时又不能太长。 如何创建： ALTER TABLE sakila.city_demo ADD KEY (city(7)); 缺点： Mysql无法使用前缀索引做ORDER BY和GROUP BY，也无法使用前缀做覆盖扫描 多列索引 当出现服务器对多个索引做相交操作时（通常有多个AND条件），通常意味着需要一个包含所有相关列的多列索引，而不是多个独立的单列索引 选择合适的索引列的顺序 （适用于B-TREE索引） 当不需要考虑排序和分组时，将选择性最高的列放在前面通常是很好的，这时候的索引的作用只是用于优化where条件的查找 聚簇索引 聚簇索引并不是一种单独的索引类型，而是一种数据的存储方式 优点： 可以把相关数据保存在一起。例如实现电子邮件时，可以根据用户ID来聚集数据，这样只需要从磁盘读取少数的数据页就能获取某个用户的全部邮件。如果没有使用聚族索引，则每封邮件都可能导致一次磁盘I/O； 数据访问更快。聚族索引将索引和数据保存在同一个B-Tree中，因此从聚族索引中获取数据通常比在非聚族索引中查找更快。 使用覆盖索引扫描的查询可以直接使用节点中的主键值。 缺点： 聚簇数据最大限度的提高了I/O密集型应用的性能，但如果数据全部都放在内存中，则访问的顺序就没有那么重要了，聚簇索引也就没有那么优势了； 插入速度严重依赖于插入顺序。按照主键的顺序插入是加载数据到InnoDB表中速度最快的方式。但如果不是按照主键顺序加载数据，那么在加载完成后最好使用OPTIMIZE TABLE命令重新组织一下表。 更新聚簇索引列的代价很高，因为会强制InnoDB将每个被更新的行移动到新的位置。 基于聚簇索引的表在插入新行，或者主键被更新导致需要移动行的时候，可能面临“页分裂”的问题。当行的主键值要求必须将这一行插入到某个已满的页中时，存储引擎会将该页分裂成两个页面来容纳该行，这就是一次分裂操作。页分裂会导致表占用更多的磁盘空间。 聚簇索引可能导致全表扫描变慢，尤其是行比较稀疏，或者由于页分裂导致数据存储不连续的时候。 二级索引（非聚簇索引）可能比想象的要更大，因为在二级索引的叶子节点包含了引用行的主键列。 二级索引访问需要两次索引查找，而不是一次。 InnoDB的二级索引的叶子节点中存储的不是“行指针”。而是主键值，并以此作为指向行的“指针”。这样的策略减少了当出现行移动或者数据页分裂时二级索引的维护工作。 使用InnoDB时应该尽可能的按照按键顺序插入数据，并且尽可能的使用单调增加的聚簇键的值来插入新行。 覆盖索引 定义： 如果一个索引包含所有需要查询的字段的值，我们称之为覆盖索引。 优点： 索引条目通常远小于数据行大小，所以如果只需要读取索引，那MySQL就会极大地减少数据访问量。这对缓存的负载非常重要，因为这种情况下响应时间大部分花费在数据拷贝上。覆盖索引对于I/O密集型的应用也有帮助，因为索引比数据更小，更容易全部放入内存中（这对于MyISAM尤其正确，因为MyISAM能压缩索引以变得更小）。 因为索引是按照列值顺存储的（至少在单个页内是如此），所以对于I/O密集型的范围查询会比随机从磁盘读取每一行数据的I/O要少得多。对于某些存储引擎，例如MyISAM和Percona XtraDB，甚至可以通过OPTIMIZE命令使得索引完全顺序排列，这让简单的范围查询能使用完全顺序的索引访问。 一些存储引擎如MyISAM在内存中只缓存索引，数据则依赖于操作系统来缓存，因此要访问数据需要一次系统调用。这可能会导致严重的性能问题，尤其是那些系统调用占了数据访问中的最大开销的场景。 由于InnoDB的聚簇索引，覆盖索引对InnoDB表特别有用。InnoDB的二级索引在叶子节点中保存了行的主键值，所以如果二级主键能够覆盖查询，则可以避免对主键索引的二次查询。 MySQL只能使用B-Tree索引做覆盖索引 使用索引扫描来做排序 如果EXPLAIN出来的type列的值为“index”,则说明Mysql使用了索引扫描来做排序 只有当索引的列顺序和ORDER BY子句的顺序完全一致，并且所有列的排序方向（倒序或正序）都一样时，MySQL才能够使用索引来对结果做排序。如果查询需要关联多张表，则只有当ORDER BY子句引用的字段全部为第一个表时，才能使用索引做排序。OEDER BY子句和查找型查询的限制是一样的：需要满足索引的最左前缀的要求；否则，MySQL都需要执行排序操作，而无法利用索引排序。 有一种情况下ORDER BY子句可以不满足索引的最左前缀的要求，就是前导列为常量的时候。如果WHERE子句或者JOIN子句中对这些列制定了常量，就可以“弥补“索引的不足。 即使OEDER BY子句不满足索引的最左前缀的要求，也可以用于查询排序，这是因为索引的第一列被指定为一个常数 前缀压缩索引 MyISAM使用前缀压缩来减少索引的大小，从而让更多的索引可以放入内存，这在某些情况下能极大的提高性能。默认值压缩字符串，但通过参数设置也可以对整数做压缩。 压缩使用更少的空间，待见是某些操作可能更慢。因为每个值的压缩前缀都依赖前面的值，所以MyISAM查找时无法在所言块中使用二分查找而只能从头开始扫描。正序的扫描速度还不错，但如果时倒序就是很好了。测试表明，对于cpu密集型应用，因为扫描需要随机查找，压缩索引使得MyISAM在索引查找上要慢好几倍。压缩索引的倒序扫描就更慢了。压缩索引需要在cpu内存资源与磁盘之间做平衡。压缩索引可能只需要十分之一大小的磁盘空间，如果是I/O密集型应用，对某些查询带来的好处会比成本多很多。 可以在create table语句中指定PACK_KEYS参数来控制索引压缩的方式。 冗余和重复索引 重复索引是指在相同的列上按照相同的顺序创建的相同类型的额索引。应该避免这样创建索引，发现以后也应该立即移除。 如果创建了索引（A,B），再创建索引（A）就是冗余索引，因为这只是前一个索引的前缀索引。 一般来说。增加索引将会导致INSERT/UODATE/DELETE等操作的速度变慢，特别是当新增索引后导致了内存瓶颈的时候 索引和锁 索引和锁可以让查询锁定更少的行。如果你的查询从不访问那些不需要访问的行，那么就会锁定更少的行，从两个方面来看这对性能都有好处。首先，虽然innodb的行锁效率很高，内存使用也很少，但是锁定行的时候仍然会带来额外的开销，其次，锁定超过需要的行会增加锁竞争，并减少并发性。 innodb只有在访问行的时候才会对其加锁，而索引能够减少innodb访问的行数，从而减少锁的数量。但只有当innodb在存储引擎能够过滤掉不需要的行时才有效。如果索引无法过滤掉无效的行，那么在innodb检索到数据并返回给服务器层以后，MySQL服务器才能应用WHERE子句。这时候，已经无法避免锁定行了：inno代表可以在服务器端过滤掉行后就释放锁，但是在早期的MySQL版本中，innodb只有在事务提交后才能释放锁。 ","date":"2024-02-17","objectID":"/mysql/:0:6","tags":["Mysql"],"title":"Mysql用法","uri":"/mysql/"},{"categories":["Mysql"],"content":"查询优化 优化数据访问 是否向数据库请求了不需要的数据 查询不需要的记录：加limit 多表关联时返回全部列 总是取出全部列 重复查询相同的数据：做数据缓存 查询执行的基础 客户端发送一条查询给服务器。 服务器先检查查询缓存，如果命中缓存，则立刻返回存储在缓存中的记过。否则进入下一阶段。 服务器进行SQL解析，预处理，再由优化器生成对应的执行计划。 MYSQL根据优化器生成的执行计划，调用存储引擎的API来执行查询。 将结果返回给客户端。 mysql客户端和服务器之间的通信协议 是“半双工”的，这意味着，在任何一个时刻要么是由服务器向客户端发送数据，要么是由客户端向服务器发送数据，这两个动作不能懂事发生。所以我们也无需将一个消息切成小块独立来发送。 这种协议让mysql通信简单快速，但也从很多地方限制了mysql。一个明显的限制是，这意味着没法进行流量控制。一旦一段开始发生消息，另一端要接受完整个消息才能响应它。这就像是来回抛球的游戏：在任何时刻，只有一个人能够控制球，而且只有控制球的人才能将消息抛回去（发送消息）。 客户端用一个单独的数据包将查询传给服务器。这也是为什么当查询语句很长的时候，参数max_allowed_packet就非常重要了。一旦客户端发送了请求，它能做的事情就只是等待结果了。 相反的，一般服务器响应给用户的数据通常很多，由多个数据包组成。当服务器开始响应客户端请求时，客户端必须完整地接受整个返回结果，而不能简单地只取前几条结果，然后让服务器停止发送数据。这种情况下，客户端若接受完整的结果，然后取前面几条需要的结果，或者接收完几调结果后就粗暴地断开链接，都不是好主意。这也是在必要的时候一定要在查询中加上limit限制的原因。 换一种方式解释这种行为：当客户端从服务器取数据时，看起来是一个拉数据的过程，但实际上是mysql在向客户端推送数据的过程。客户端不断地接收从服务器推送的数据，客户端也没法让服务器停下来。客户端像是“从消防水管喝水”。 多少连接mysql的库函数都可以获得全部结果集并缓存到内存里，还可以朱行获取需要的数据。默认一般是获得全部结果集并缓存在内存中。mysql通常需要等所有的数据都已经发送给客户端才能释放这条查询所占用的资源，所以接受全部结果并缓存通常可以减少服务器的压力，让查询能够早点结束、早点释放相应资源。 当使用多数链接mysql的库函数从mysql获取数据时，其结果看起来都像是从mysql服务器获取数据，二实际上都是从这个库函数的缓存获取数据。多数情况下没什么问题，但是如果需要范湖一个很大的结果集的时候，这样做并不好，因为库函数会花很多时间和内存来存储所有的结果集。如果能够尽早开始处理这些结果集，就能大大减少内存的消耗，这种情况下可以不适用缓存来记录结果而是直接处理。这样做的缺点是，对于服务器来说需要查询完成后才能释放资源，所以在客户端交互的整个过程中，服务器的资源都是被这个查询锁占用的。 查询缓存 在解析一个查询语句之前，如果查询缓存是打开的，那么mysql会优先检查这个查询是否命中查询缓存中的数据。这个检查是通过一个对大小写敏感的哈希查找实现的。查询和缓存中的查询即使只是一个字节不同，那也不会匹配缓存结果，这种情况下查询就会进入下一阶段的处理。 如果当前的查询恰好命中了查询缓存，那么在返回查询结果之前mysql会检查一次用户权限。这仍然是无需解析查询SQL语句的，因为在查询缓存中已经存放了当前查询需要访问的表信息。如果权限没有问题，mysql会跳过所有其他阶段，直接从缓存中拿到结果并返回给客户端。这种情况下，查询不会被解析，不用生成执行计划，不会被执行。 change buffer的使用场景 普通索引的所有场景，使用 change buffer 都可以起到加速作用吗？ 因为 merge 的时候是真正进行数据更新的时刻，而 change buffer 的主要目的就是将记录的变更动作缓存下来，所以在一个数据页做 merge 之前，change buffer 记录的变更越多（也就是这个页面上要更新的次数越多），收益就越大。 因此，对于写多读少的业务来说，页面在写完以后马上被访问到的概率比较小，此时change buffer 的使用效果最好。这种业务模型常见的就是账单类、日志类的系统。 ","date":"2024-02-17","objectID":"/mysql/:0:7","tags":["Mysql"],"title":"Mysql用法","uri":"/mysql/"},{"categories":["Mysql"],"content":"索引选择和实践 这两类索引在查询能力上是没差别的，主要考虑的是对更新性能的影响。所以，我建议你尽量选择普通索引。 尽量使用普通索引，然后把 change buffer 尽量开大，以确保这个“历史数据”表的数据写入速度。 ","date":"2024-02-17","objectID":"/mysql/:0:8","tags":["Mysql"],"title":"Mysql用法","uri":"/mysql/"},{"categories":["Mysql"],"content":"普通索引和唯一索引，应该怎么选择？ 查询过程 对于普通索引来说，查找到满足条件的第一个记录 (5,500) 后，需要查找下一个记录，直到碰到第一个不满足 k=5 条件的记录。 对于唯一索引来说，由于索引定义了唯一性，查找到第一个满足条件的记录后，就会停止继续检索。 ","date":"2024-02-17","objectID":"/mysql/:0:9","tags":["Mysql"],"title":"Mysql用法","uri":"/mysql/"},{"categories":["Mysql"],"content":"更新过程 当需要更新一个数据页时，如果数据页在内存中就直接更新，而如果这个数据页还没有在内存中的话，在不影响数据一致性的前提下，InooDB 会将这些更新操作缓存在 changebuffer 中，这样就不需要从磁盘中读入这个数据页了。在下次查询需要访问这个数据页的时候，将数据页读入内存，然后执行 change buffer 中与这个页有关的操作。通过这种方式就能保证这个数据逻辑的正确性。 change buffer，实际上它是可以持久化的数据。也就是说，change buffer 在内存中有拷贝，也会被写入到磁盘上。 什么条件下可以使用change buffer呢？ 唯一索引的更新就不能使用 change buffer，实际上也只有普通索引可以使用。 change buffer 的大小，可以通过参数 innodb_change_buffer_max_size 来动态设置。这个参数设置为 50 的时候，表示 change buffer 的大小最多只能占用 buffer pool 的 50%。 如果要在这张表中插入一个新记录 (4,400) 的话，InnoDB 的处理流程是怎样的？ 这个记录要更新的目标页在内存中。这时，InnoDB 的处理流程如下： 对于唯一索引来说，找到 3 和 5 之间的位置，判断到没有冲突，插入这个值，语句执行结束； 对于普通索引来说，找到 3 和 5 之间的位置，插入这个值，语句执行结束。 这个记录要更新的目标页不在内存中。这时，InnoDB 的处理流程如下： 对于唯一索引来说，需要将数据页读入内存，判断到没有冲突，插入这个值，语句执行结束； 对于普通索引来说，则是将更新记录在 change buffer，语句执行就结束了。 将数据从磁盘读入内存涉及随机 IO 的访问，是数据库里面成本最高的操作之一。changebuffer 因为减少了随机磁盘访问，所以对更新性能的提升是会很明显的。 Change buffer和redo log redo log 主要节省的是随机写磁盘的 IO 消耗（转成顺序写），而 change buffer 主要节省的则是随机读磁盘的 IO 消耗。 ","date":"2024-02-17","objectID":"/mysql/:0:10","tags":["Mysql"],"title":"Mysql用法","uri":"/mysql/"},{"categories":["Mysql"],"content":"索引下推 使用ICP的情况下，查询过程： 存储引擎读取索引记录（不是完整的行记录）； 判断WHERE条件部分能否用索引中的列来做检查，条件不满足，则处理下一行索引记录（+1） 条件满足，使用索引中的主键去定位并读取完整的行记录（就是所谓的回表）； 存储引擎把记录交给Server层，Server层检测该记录是否满足WHERE条件的其余部分。 ","date":"2024-02-17","objectID":"/mysql/:0:11","tags":["Mysql"],"title":"Mysql用法","uri":"/mysql/"},{"categories":["Mysql"],"content":"最左前缀原则 当你创建了一个联合索引，该索引的任何最左前缀都可以用于查询 mysql会一直向右匹配直到遇到范围查询(\u003e、\u003c、between、like)就停止匹配，比如a = 1 and b = 2 and c \u003e 3 and d = 4 如果建立(a,b,c,d)顺序的索引，d是用不到索引的，如果建立(a,b,d,c)的索引则都可以用到，a,b,d的顺序可以任意调整。 ","date":"2024-02-17","objectID":"/mysql/:0:12","tags":["Mysql"],"title":"Mysql用法","uri":"/mysql/"},{"categories":["Mysql"],"content":"前缀索引 使用前缀索引，定义好长度，就可以做到既节省空间，又不用额外增加太多的查询成本。 我们在建立索引时关注的是区分度，区分度越高越好。因为区分度越高，意味着重复的键值越少。因此，我们可以通过统计索引上有多少个不同的值来判断要使用多长的前缀。 怎么确定前缀长度？ 计算出列上有多少个不同的值 Select count(distinct email) as L from SUSer; 依次选取不同长度的前缀来看这个值 Select count(distinct left(email,4)) as L4 count(distinct left(email,5)) as L5 from SUSer; 要预先设定一个可以接受的损失比例，比如 5%。然后，在返回的 L4~L5 中，找出不小于 L * 95% 的值 前缀索引对覆盖索引的影响 使用前缀索引就用不上覆盖索引对查询性能的优化了，这也是你在选择是否使用前缀索引时需要考虑的一个因素。 ","date":"2024-02-17","objectID":"/mysql/:0:13","tags":["Mysql"],"title":"Mysql用法","uri":"/mysql/"},{"categories":["Mysql"],"content":"基于主键索引和普通索引的查询有什么区别？ 如果语句是 select * from T where ID=500，主键查询方式，则只需要搜索 ID 这棵B+ 树； 如果语句是 select * from T where k=5，普通索引查询方式，则需要先搜索 k 索引树，得到 ID 的值为 500，再到 ID 索引树搜索一次。这个过程称为回表。 ","date":"2024-02-17","objectID":"/mysql/:0:14","tags":["Mysql"],"title":"Mysql用法","uri":"/mysql/"},{"categories":["Mysql"],"content":"索引的类型 主键索引（聚簇索引）：主键索引的叶子节点存的是整行数据 非主键索引（二级索引）：非主键索引的叶子节点内容是主键的值 哪些场景应该使用自增主键？ 自增主键的插入数据模式，正符合了我们前面提到的递增插入的场景。每次插入一条新记录，都是追加操作，都不涉及到挪动其他记录，也不会触发叶子节点的分裂。主键长度越小，普通索引的叶子节点就越小，普通索引占用的空间也就越小。 有些业务的场景需求是这样的：1. 只有一个索引；2. 该索引必须是唯一索引。此时更适合用业务字段作为主键 ","date":"2024-02-17","objectID":"/mysql/:0:15","tags":["Mysql"],"title":"Mysql用法","uri":"/mysql/"},{"categories":["Mysql"],"content":"Mysql为什么有时候会选错索引？ 优化器的逻辑 扫描行数是怎么判断的？ MySQL 在真正开始执行语句之前，并不能精确地知道满足这个条件的记录有多少条，而只能根据统计信息来估算记录数。 MySQL 是怎样得到索引的基数的呢？ InnoDB 默认会选择 N 个数据页，统计这些页面上的不同值，得到一个平均值，然后乘以这个索引的页面数，就得到了这个索引的基数。 当变更的数据行数超过1/M 的时候，会自动触发重新做一次索引统计。 在 MySQL 中，有两种存储索引统计的方式，可以通过设置参数 innodb_stats_persistent的值来选择： 设置为 on 的时候，表示统计信息会持久化存储。这时，默认的 N 是 20，M 是 10。 设置为 off 的时候，表示统计信息只存储在内存中。这时，默认的 N 是 8，M 是 16。 重新统计索引信息： analyze table t 索引选择异常和处理 采用 force index 强行选择一个索引。 我们可以考虑修改语句，引导 MySQL 使用我们期望的索引。 在有些场景下，我们可以新建一个更合适的索引，来提供给优化器做选择，或删掉误用的索引。 ","date":"2024-02-17","objectID":"/mysql/:0:16","tags":["Mysql"],"title":"Mysql用法","uri":"/mysql/"},{"categories":["秒杀"],"content":"这篇文章展示了秒杀.","date":"2024-02-17","objectID":"/miaosha/","tags":["秒杀"],"title":"秒杀","uri":"/miaosha/"},{"categories":["秒杀"],"content":"瞬时高并发 ","date":"2024-02-17","objectID":"/miaosha/:1:0","tags":["秒杀"],"title":"秒杀","uri":"/miaosha/"},{"categories":["秒杀"],"content":"页面静态化 cdn加速 ","date":"2024-02-17","objectID":"/miaosha/:2:0","tags":["秒杀"],"title":"秒杀","uri":"/miaosha/"},{"categories":["秒杀"],"content":"秒杀按钮 js文件控制 定时器 ","date":"2024-02-17","objectID":"/miaosha/:3:0","tags":["秒杀"],"title":"秒杀","uri":"/miaosha/"},{"categories":["秒杀"],"content":"读多写少 redis ","date":"2024-02-17","objectID":"/miaosha/:4:0","tags":["秒杀"],"title":"秒杀","uri":"/miaosha/"},{"categories":["秒杀"],"content":"缓存问题 ","date":"2024-02-17","objectID":"/miaosha/:5:0","tags":["秒杀"],"title":"秒杀","uri":"/miaosha/"},{"categories":["秒杀"],"content":"缓存击穿 缓存预热 分布式锁 ","date":"2024-02-17","objectID":"/miaosha/:5:1","tags":["秒杀"],"title":"秒杀","uri":"/miaosha/"},{"categories":["秒杀"],"content":"缓存穿透 布隆过滤器： 适用于缓存更新很少的场景 将商品id加入缓存，设置超时时间尽量短 ","date":"2024-02-17","objectID":"/miaosha/:5:2","tags":["秒杀"],"title":"秒杀","uri":"/miaosha/"},{"categories":["秒杀"],"content":"库存问题 ","date":"2024-02-17","objectID":"/miaosha/:6:0","tags":["秒杀"],"title":"秒杀","uri":"/miaosha/"},{"categories":["秒杀"],"content":"预扣库存 数据库扣减库存 数据库的乐观锁：Stock\u003e0在更新 问题： 死锁问题 容易造成系统雪崩 redis扣减库存 非原子操作 Lua脚本扣减库存 ","date":"2024-02-17","objectID":"/miaosha/:6:1","tags":["秒杀"],"title":"秒杀","uri":"/miaosha/"},{"categories":["秒杀"],"content":"分布式锁 ","date":"2024-02-17","objectID":"/miaosha/:7:0","tags":["秒杀"],"title":"秒杀","uri":"/miaosha/"},{"categories":["秒杀"],"content":"Setnx加锁 ","date":"2024-02-17","objectID":"/miaosha/:7:1","tags":["秒杀"],"title":"秒杀","uri":"/miaosha/"},{"categories":["秒杀"],"content":"set加锁 lockKey requestId NX PX expireTime ","date":"2024-02-17","objectID":"/miaosha/:7:2","tags":["秒杀"],"title":"秒杀","uri":"/miaosha/"},{"categories":["秒杀"],"content":" 通过requestId，只释放自己的锁，不允许释放别人加的锁 ","date":"2024-02-17","objectID":"/miaosha/:7:3","tags":["秒杀"],"title":"秒杀","uri":"/miaosha/"},{"categories":["秒杀"],"content":"自旋锁 解决均匀分布的秒杀问题 ","date":"2024-02-17","objectID":"/miaosha/:7:4","tags":["秒杀"],"title":"秒杀","uri":"/miaosha/"},{"categories":["秒杀"],"content":"Redission 在不同的节点上使用单个实例获取锁的方式去获得锁，且每次获取锁都有超时时间，如果请求超时，则认为该节点不可用。当应用服务成功获取锁的Redis节点超过半数（N/2+1，N为节点数)时，并且获取锁消耗的实际时间不超过锁的过期时间，则获取锁成功 ","date":"2024-02-17","objectID":"/miaosha/:7:5","tags":["秒杀"],"title":"秒杀","uri":"/miaosha/"},{"categories":["秒杀"],"content":"mq异步处理 ","date":"2024-02-17","objectID":"/miaosha/:8:0","tags":["秒杀"],"title":"秒杀","uri":"/miaosha/"},{"categories":["秒杀"],"content":"下单功能 消息丢失问题 Job,增加重试 消息发送表 重复消费问题 消息处理表 注意 注意：下单和写消息处理表，需要在同一个事务当中，保证原子操作 垃圾消息问题 Job重试的时候，需要判断一下消息发送表该消息的发送次数是否达到最大限制 延迟消费问题 下单消息生产者先生成订单，向延迟队列发送消息 ","date":"2024-02-17","objectID":"/miaosha/:8:1","tags":["秒杀"],"title":"秒杀","uri":"/miaosha/"},{"categories":["秒杀"],"content":"如何限流 ","date":"2024-02-17","objectID":"/miaosha/:9:0","tags":["秒杀"],"title":"秒杀","uri":"/miaosha/"},{"categories":["秒杀"],"content":"对同一用户限流 ","date":"2024-02-17","objectID":"/miaosha/:9:1","tags":["秒杀"],"title":"秒杀","uri":"/miaosha/"},{"categories":["秒杀"],"content":"对同一ip限流 ","date":"2024-02-17","objectID":"/miaosha/:9:2","tags":["秒杀"],"title":"秒杀","uri":"/miaosha/"},{"categories":["秒杀"],"content":"对接口限流 ","date":"2024-02-17","objectID":"/miaosha/:9:3","tags":["秒杀"],"title":"秒杀","uri":"/miaosha/"},{"categories":["秒杀"],"content":"加验证码 用户体验比较差 ","date":"2024-02-17","objectID":"/miaosha/:9:4","tags":["秒杀"],"title":"秒杀","uri":"/miaosha/"},{"categories":["秒杀"],"content":"提高业务门槛 ","date":"2024-02-17","objectID":"/miaosha/:9:5","tags":["秒杀"],"title":"秒杀","uri":"/miaosha/"},{"categories":["Mysql"],"content":"这篇文章展示了Mysql查询优化用法.","date":"2024-02-16","objectID":"/mysql_optimize/","tags":["Mysql"],"title":"Mysql查询优化","uri":"/mysql_optimize/"},{"categories":["Mysql"],"content":"查询分页数据方法 使用数据库提供 SQL语句 select * from table_name limit 0,5 语句样式： MySQL中,可用如下方法: SELECT * FROM 表名称 LIMIT M,N 适应场景： 适用于数据量较少的情况(元组百/千级) 原因/缺点： 全表扫描，速度会很慢，且有的数据库结果集返回不稳定(如某次返回1,2,3,另外的一次返回2,1,3)，Limit限制的是从结果集的M位置处取出N条输出，其余抛弃。 建立主键或唯一索引，利用索引 语句样式：可用如下方法：SELECT * FROM 表名称 WHERE pk_id \u003e (pageNum*10) LIMIT M 适应场景：适用于数据量多的情况(元组数上万) 原因：索引扫描，速度会很快。有朋友提出：因为数据查询出来并不是按照pk_id排序的，所以会有漏掉数据的情况，只能方法3 基于索引在排序 语句样式：可用如下方法： SELECT * FROM 表名称 WHERE pk_id \u003e (pageNum*10) ORDER BY pk_id ASC LIMIT M 适应场景： 适用于数据量多的情况(元组数上万)，最好ORDER BY后的列对象是主键或唯一索引，使得ORDER BY操作能利用索引被消除但结果集是稳定的 原因：索引扫描，速度会很快。 基于索引使用prepare（第一个问号表示pageNum，第二个？表示每页元组数） 语句样式：MySQL中,可用如下方法: PREPARE stmt_name FROM SELECT * FROM 表名称 WHERE pk_id \u003e (？* ？) ORDER BY pk_id ASC LIMIT M 适应场景：大数据量 原因：索引扫描，速度会很快。prepare语句又比一般的查询语句快一点。 利用MySQL支持ORDER操作可以利用索引快速定位部分元组，避免全表扫描 比如： 读第1000到1019行元组(pk是主键/唯一键). SELECT * FROM your_table WHERE pk\u003e=1000 ORDER BY pk ASC LIMIT 0,20 利用\"子查询/连接+索引\"快速定位元组的位置，然后再读取元组。 道理同方法5。如(id是主键/唯一键，$page、$pagesize是变量): 利用子查询示例: SELECT * FROM your_table WHERE id \u003c= (SELECT id FROM your_table ORDER BY id desc LIMIT ($page-1)*$pagesize ORDER BY id desc LIMIT $pagesize 利用连接示例: SELECT * FROM your_table AS t1 JOIN (SELECT id FROM your_table ORDER BY id desc LIMIT ($page-1)*$pagesize AS t2 WHERE t1.id \u003c= t2.id ORDER BY t1.id desc LIMIT $pagesize; ","date":"2024-02-16","objectID":"/mysql_optimize/:1:0","tags":["Mysql"],"title":"Mysql查询优化","uri":"/mysql_optimize/"},{"categories":["Mysql"],"content":"优化方式 直接用limit start, count分页语句： 对limit分页问题的性能优化方法 利用表的覆盖索引来加速分页查询：我们都知道，利用了索引查询的语句中如果只包含了那个索引列（覆盖索引），那么这种情况会查询很快。 因为利用索引查找有优化算法，且数据就在查询索引上面，不用再去找相关的数据地址了，这样节省了很多时间。另外Mysql中也有相关的索引缓存，在并发高的时候利用缓存就效果更好了。 ","date":"2024-02-16","objectID":"/mysql_optimize/:1:1","tags":["Mysql"],"title":"Mysql查询优化","uri":"/mysql_optimize/"},{"categories":["Mysql"],"content":"短连接风暴 短连接模型存在一个风险，就是一旦数据库处理得慢一些，连接数就会暴涨。max_connections 参数，用来控制一个 MySQL 实例同时存在的连接数的上限，超过这个值，系统就会拒绝接下来的连接请求，并报错提示“Too many connections”。对于被拒绝连接的请求来说，从业务角度看就是数据库不可用。 第一种方法：先处理掉那些占着连接但是不工作的线程。 因此，如果是连接数过多，你可以优先断开事务外空闲太久的连接；如果这样还不够，再考虑断开事务内空闲太久的连接。 从数据库端主动断开连接可能是有损的，尤其是有的应用端收到这个错误后，不重新连接，而是直接用这个已经不能用的句柄重试查询。这会导致从应用端看上去，“MySQL 一直没恢复”。 第二种方法：减少连接过程的消耗。 在 MySQL 8.0 版本里，如果你启用–skip-grant-tables 参数，MySQL 会默认把 –skipnetworking 参数打开，表示这时候数据库只能被本地的客户端连接。可见，MySQL 官方对 skip-grant-tables 这个参数的安全问题也很重视。 ","date":"2024-02-16","objectID":"/mysql_optimize/:2:0","tags":["Mysql"],"title":"Mysql查询优化","uri":"/mysql_optimize/"},{"categories":["Mysql"],"content":"慢查询性能问题 ","date":"2024-02-16","objectID":"/mysql_optimize/:3:0","tags":["Mysql"],"title":"Mysql查询优化","uri":"/mysql_optimize/"},{"categories":["Mysql"],"content":"索引没有设计好； 最高效的做法就是直接执行 alter table 语句。 比较理想的是能够在备库先执行。假设你现在的服务是一主一备，主库 A、备库 B，这个方案的大致流程是这样的： 在备库 B 上执行 set sql_log_bin=off，也就是不写 binlog，然后执行 alter table 语句加上索引； 执行主备切换； 这时候主库是 B，备库是 A。在 A 上执行 set sql_log_bin=off，然后执行 alter table语句加上索引。 ","date":"2024-02-16","objectID":"/mysql_optimize/:3:1","tags":["Mysql"],"title":"Mysql查询优化","uri":"/mysql_optimize/"},{"categories":["Mysql"],"content":"SQL 语句没写好； 我们可以通过改写 SQL 语句来处理。MySQL 5.7 提供了 query_rewrite 功能，可以把输入的一种语句改写成另外一种模式。 ","date":"2024-02-16","objectID":"/mysql_optimize/:3:2","tags":["Mysql"],"title":"Mysql查询优化","uri":"/mysql_optimize/"},{"categories":["Mysql"],"content":"MySQL 选错了索引。 应急方案就是给这个语句加上 force index。 上线前，在测试环境，把慢查询日志（slow log）打开，并且把 long_query_time 设置成 0，确保每个语句都会被记录入慢查询日志； 在测试表里插入模拟线上的数据，做一遍回归测试； 观察慢查询日志里每类语句的输出，特别留意 Rows_examined 字段是否与预期一致。 你需要工具帮你检查所有的 SQL语句的返回结果。比如，你可以使用开源工具 pt-querydigest(https://www.percona.com/doc/percona-toolkit/3.0/pt-query-digest.html)。 ","date":"2024-02-16","objectID":"/mysql_optimize/:3:3","tags":["Mysql"],"title":"Mysql查询优化","uri":"/mysql_optimize/"},{"categories":["Mysql"],"content":"QPS突增问题 一种是由全新业务的 bug 导致的。假设你的 DB 运维是比较规范的，也就是说白名单是一个个加的。这种情况下，如果你能够确定业务方会下掉这个功能，只是时间上没那么快，那么就可以从数据库端直接把白名单去掉。 如果这个新功能使用的是单独的数据库用户，可以用管理员账号把这个用户删掉，然后断开现有连接。这样，这个新功能的连接不成功，由它引发的 QPS 就会变成 0。 如果这个新增的功能跟主体功能是部署在一起的，那么我们只能通过处理语句来限制。这时，我们可以使用上面提到的查询重写功能，把压力最大的 SQL 语句直接重写成\"select 1\"返回。 当然，这个操作的风险很高，需要你特别细致。它可能存在两个副作用： 如果别的功能里面也用到了这个 SQL 语句模板，会有误伤； 很多业务并不是靠这一个语句就能完成逻辑的，所以如果单独把这一个语句以 select 1的结果返回的话，可能会导致后面的业务逻辑一起失败。 所以，方案 3 是用于止血的，跟前面提到的去掉权限验证一样，应该是你所有选项里优先级最低的一个方案。 ","date":"2024-02-16","objectID":"/mysql_optimize/:4:0","tags":["Mysql"],"title":"Mysql查询优化","uri":"/mysql_optimize/"},{"categories":["Mysql"],"content":"这篇文章展示了Mysql配置用法.","date":"2024-02-15","objectID":"/mysql_config/","tags":["Mysql"],"title":"Mysql配置","uri":"/mysql_config/"},{"categories":["Mysql"],"content":"修改最大连接数 通过命令 使用数据库提供 SQL语句 set GLOBAL max_connections=100; show variables like \"max_connections\"; 及时生效，不需要重启服务，确保使用 root账号执行 修改 my.cnf vim /etc/my.cnf max_connections=100 /etc/init.d/mysqld restart 需要重启服务 ","date":"2024-02-15","objectID":"/mysql_config/:0:1","tags":["Mysql"],"title":"Mysql配置","uri":"/mysql_config/"},{"categories":["Mysql"],"content":"这篇文章展示了Mysql DDL.","date":"2024-02-14","objectID":"/mysql_ddl/","tags":["Mysql"],"title":"Mysql DDL","uri":"/mysql_ddl/"},{"categories":["Mysql"],"content":"基本语法 对数据库进行定义 create Database nba; drop Database nba; 对数据表进行定义 create table table_name; ","date":"2024-02-14","objectID":"/mysql_ddl/:0:1","tags":["Mysql"],"title":"Mysql DDL","uri":"/mysql_ddl/"},{"categories":["Mysql"],"content":"数据库约束 主键约束 作用： 唯一标识一条记录，不能重复，不能为空 一个数据表的主键只能有一个。主键可以是一个字段，也可以由多个字段复合组成。 外键 外键确保了表与表之间引用的完整性。 一个表中的外键对应另一张表的主键。外键可以重复也可以为空 唯一性约束 表明字段在表中的数值是唯一的 NOT NULL约束 表明该字段不应为空，必须有取值 DEFAULT 表明这个字段的默认值 CHECK约束 检查特定字段取值范围的有效性 ","date":"2024-02-14","objectID":"/mysql_ddl/:0:2","tags":["Mysql"],"title":"Mysql DDL","uri":"/mysql_ddl/"},{"categories":["Mysql"],"content":"设计原则 数据表的个数越少越好 数据表中的字段个数越少越好 数据表中联合主键的字段个数越少越好 使用主键和外键越多越好 关系越多，证明实体间的冗余度越低，利用度越高。 ","date":"2024-02-14","objectID":"/mysql_ddl/:0:3","tags":["Mysql"],"title":"Mysql DDL","uri":"/mysql_ddl/"},{"categories":["Mysql"],"content":"这篇文章展示了Mysql查询用法.","date":"2024-02-14","objectID":"/mysql_select/","tags":["Mysql"],"title":"Mysql查询","uri":"/mysql_select/"},{"categories":["Mysql"],"content":"查询顺序 关键字顺序不能颠倒 select ...from...where...group by...having select语句执行顺序 from \u003e where \u003e group by \u003e having \u003e select的字段 \u003e dist ","date":"2024-02-14","objectID":"/mysql_select/:1:0","tags":["Mysql"],"title":"Mysql查询","uri":"/mysql_select/"},{"categories":["Mysql"],"content":"数据过滤 ","date":"2024-02-14","objectID":"/mysql_select/:2:0","tags":["Mysql"],"title":"Mysql查询","uri":"/mysql_select/"},{"categories":["Mysql"],"content":"比较运算符 =、\u003c\u003e、\u003c、\u003c=、\u003e、\u003e=、!\u003c、BETWEEN、IS NULL ","date":"2024-02-14","objectID":"/mysql_select/:2:1","tags":["Mysql"],"title":"Mysql查询","uri":"/mysql_select/"},{"categories":["Mysql"],"content":"逻辑运算符 AND、 OR、 IN、 NOT ","date":"2024-02-14","objectID":"/mysql_select/:2:2","tags":["Mysql"],"title":"Mysql查询","uri":"/mysql_select/"},{"categories":["Mysql"],"content":"通配符 如果要让索引生效，则 LIKE后面不能以%开头。 ","date":"2024-02-14","objectID":"/mysql_select/:2:3","tags":["Mysql"],"title":"Mysql查询","uri":"/mysql_select/"},{"categories":["Mysql"],"content":"排序方式 FileSort：一般在内存中排序，占用 CPU较多。如果待排结果较大，会产生临时文件 I/O到磁盘进行排序，效率较低 Index：效率更高，索引可以保证数据的有序性 ","date":"2024-02-14","objectID":"/mysql_select/:2:4","tags":["Mysql"],"title":"Mysql查询","uri":"/mysql_select/"},{"categories":["Mysql"],"content":"SQL函数 ","date":"2024-02-14","objectID":"/mysql_select/:3:0","tags":["Mysql"],"title":"Mysql查询","uri":"/mysql_select/"},{"categories":["Mysql"],"content":"算术函数 函数名 定义 ABS() 取绝对值 MOD() 取余 ROUND() 四舍五入 ","date":"2024-02-14","objectID":"/mysql_select/:3:1","tags":["Mysql"],"title":"Mysql查询","uri":"/mysql_select/"},{"categories":["Mysql"],"content":"字符串函数 函数名 定义 CONTACT() 多个字符串拼接 LENGTH() 计算字段的长度，一个汉字算三个字符 CHAR_LENGTH() 计算字段的长度，汉字、数字、字母算一个字符 LOWER() 将字符串的字符转化为小写 UPPER() 将字符串的字符转化为大写 REPLACE() 替换函数 SUBSTRING() 截取字符串 ","date":"2024-02-14","objectID":"/mysql_select/:3:2","tags":["Mysql"],"title":"Mysql查询","uri":"/mysql_select/"},{"categories":["Mysql"],"content":"日期函数 函数名 定义 CURRENT_DATE() 取绝对值 CURRENT_TIME() 取余 CURRENT_TIMESTAMP() 四舍五入 EXTRACT() 抽取具体的年、月、日 DATE() 日期 YEAR() 年份 MONTH() 月份 DAY() 天数 HOUR() 时 MINUTE() 分 SECOND() 秒 ","date":"2024-02-14","objectID":"/mysql_select/:3:3","tags":["Mysql"],"title":"Mysql查询","uri":"/mysql_select/"},{"categories":["Mysql"],"content":"转换函数 函数名 定义 CAST() 数据类型转化 COALESCE() 返回第一个非空数值 ","date":"2024-02-14","objectID":"/mysql_select/:3:4","tags":["Mysql"],"title":"Mysql查询","uri":"/mysql_select/"},{"categories":["Mysql"],"content":"命名规范 关键字和函数和名称全部大写 数据库名、表名、字段名全部小写 SQL语句必须以分号结尾 ","date":"2024-02-14","objectID":"/mysql_select/:3:5","tags":["Mysql"],"title":"Mysql查询","uri":"/mysql_select/"},{"categories":["Mysql"],"content":"聚集函数 函数名 定义 COUNT() 总行数 MAX() 最大值 MIN() 最小值 SUM() 求和 AVG() 平均值 ","date":"2024-02-14","objectID":"/mysql_select/:3:6","tags":["Mysql"],"title":"Mysql查询","uri":"/mysql_select/"},{"categories":["Mysql"],"content":"WHERE和 HAVING区别 过滤分组使用 HAVING. 数据行使用 WHERE ","date":"2024-02-14","objectID":"/mysql_select/:3:7","tags":["Mysql"],"title":"Mysql查询","uri":"/mysql_select/"},{"categories":["Mysql"],"content":"子查询 ","date":"2024-02-14","objectID":"/mysql_select/:4:0","tags":["Mysql"],"title":"Mysql查询","uri":"/mysql_select/"},{"categories":["Mysql"],"content":"非关联子查询 子查询从数据表中查询了数据结果，如果这个数据结果只执行了一次，然后这个数据结果作为主查询的条件进行执行。 ","date":"2024-02-14","objectID":"/mysql_select/:4:1","tags":["Mysql"],"title":"Mysql查询","uri":"/mysql_select/"},{"categories":["Mysql"],"content":"Exist子查询 ","date":"2024-02-14","objectID":"/mysql_select/:4:2","tags":["Mysql"],"title":"Mysql查询","uri":"/mysql_select/"},{"categories":["Mysql"],"content":"集合比较子查询 IN 判断是否在集合中 ANY 需跟比较操作符一起使用 ALL 需跟比较操作符一起使用 SOME ANY的别名 ","date":"2024-02-14","objectID":"/mysql_select/:4:3","tags":["Mysql"],"title":"Mysql查询","uri":"/mysql_select/"},{"categories":["Mysql"],"content":"关联子查询 如果子查询需要执行多次，即采用循环的方式，先从外部查询开始，每次都传入子查询进行查询，然后再将结果反馈给外部 ","date":"2024-02-14","objectID":"/mysql_select/:4:4","tags":["Mysql"],"title":"Mysql查询","uri":"/mysql_select/"},{"categories":["Mysql"],"content":"in和 exist效率 SELECT* FROM A WHERE cc IN(SELECT cc FROM B) SELECT* FROM A WHERE cc EXIST(SELECT cc FROM B WHERE B.cc=A.cc) 如果对 cc列都建立了索引的情况下，需判断表 A和表 B的大小。 如果 A\u003eB大，那么 IN子查询的效率要比 EXIST子查询效率高。 ","date":"2024-02-14","objectID":"/mysql_select/:4:5","tags":["Mysql"],"title":"Mysql查询","uri":"/mysql_select/"},{"categories":["Mysql"],"content":"连接 ","date":"2024-02-14","objectID":"/mysql_select/:5:0","tags":["Mysql"],"title":"Mysql查询","uri":"/mysql_select/"},{"categories":["Mysql"],"content":"自连接 ","date":"2024-02-14","objectID":"/mysql_select/:5:1","tags":["Mysql"],"title":"Mysql查询","uri":"/mysql_select/"},{"categories":["Mysql"],"content":"笛卡尔积 ","date":"2024-02-14","objectID":"/mysql_select/:5:2","tags":["Mysql"],"title":"Mysql查询","uri":"/mysql_select/"},{"categories":["Mysql"],"content":"外连接 ","date":"2024-02-14","objectID":"/mysql_select/:5:3","tags":["Mysql"],"title":"Mysql查询","uri":"/mysql_select/"},{"categories":["Mysql"],"content":"非等值连接 ","date":"2024-02-14","objectID":"/mysql_select/:5:4","tags":["Mysql"],"title":"Mysql查询","uri":"/mysql_select/"},{"categories":["Mysql"],"content":"等值连接 ","date":"2024-02-14","objectID":"/mysql_select/:5:5","tags":["Mysql"],"title":"Mysql查询","uri":"/mysql_select/"},{"categories":["Mysql"],"content":"图 封装了底层和数据表的借口，简化一张表或者多张表的数据结果集 ","date":"2024-02-14","objectID":"/mysql_select/:6:0","tags":["Mysql"],"title":"Mysql查询","uri":"/mysql_select/"},{"categories":["Mysql"],"content":"创建视图 create view view_name As select column1, column2 from table; ","date":"2024-02-14","objectID":"/mysql_select/:6:1","tags":["Mysql"],"title":"Mysql查询","uri":"/mysql_select/"},{"categories":["Mysql"],"content":"修改视图 Alter view view_name As select column1, column2 from table; ","date":"2024-02-14","objectID":"/mysql_select/:6:2","tags":["Mysql"],"title":"Mysql查询","uri":"/mysql_select/"},{"categories":["Mysql"],"content":"删除视图 drop view view_name ","date":"2024-02-14","objectID":"/mysql_select/:6:3","tags":["Mysql"],"title":"Mysql查询","uri":"/mysql_select/"},{"categories":["Mysql"],"content":"这篇文章展示了Mysql Procedure.","date":"2024-02-13","objectID":"/mysql_procedure/","tags":["Mysql"],"title":"Mysql Procedure","uri":"/mysql_procedure/"},{"categories":["Mysql"],"content":"基本语法 创建存储过程 Create Procedure name BEGIN 执行语句 END 更新存储过程 Alter Procedure name BEGIN 执行语句 END 删除存储过程 Drop Procedure name ","date":"2024-02-13","objectID":"/mysql_procedure/:0:1","tags":["Mysql"],"title":"Mysql Procedure","uri":"/mysql_procedure/"},{"categories":["Mysql"],"content":"参数类型 参数类型 是否返回 In 否 Out 是 InOut 是 ","date":"2024-02-13","objectID":"/mysql_procedure/:0:2","tags":["Mysql"],"title":"Mysql Procedure","uri":"/mysql_procedure/"},{"categories":["Mysql"],"content":"流控制语句 BEGIN … END 语句 DECLARE 声明变量 SET 赋值语句 SELECT … INTO 为变量赋值 IF…THEN…ENDIF 条件判断语句 CASE多条件判断语句 LOOP、 LEAVE和 ITERATE：LOOP循环语句，使用LEAVE可以跳出循环，使用ITERATE则可以进入下一次循环 REPEAT…UNTIL…END REPEAT：循环语句 WHILE…DO…END WHILE：循环语句 ","date":"2024-02-13","objectID":"/mysql_procedure/:0:3","tags":["Mysql"],"title":"Mysql Procedure","uri":"/mysql_procedure/"},{"categories":["Mysql"],"content":"优缺点 优点 一次编译多次使用 提升 SQL的执行效率，减少开发工作量 安全性强 减少网络传输量 ","date":"2024-02-13","objectID":"/mysql_procedure/:0:4","tags":["Mysql"],"title":"Mysql Procedure","uri":"/mysql_procedure/"},{"categories":["Mysql"],"content":"缺点 可移植性差 调试困难 版本管理困难 不适合高并发的场景 ","date":"2024-02-13","objectID":"/mysql_procedure/:0:5","tags":["Mysql"],"title":"Mysql Procedure","uri":"/mysql_procedure/"},{"categories":["Mysql"],"content":"这篇文章展示了Mysql事务.","date":"2024-02-13","objectID":"/mysql_transaction/","tags":["Mysql"],"title":"Mysql事务","uri":"/mysql_transaction/"},{"categories":["Mysql"],"content":"ACID原则 A原子性 数据处理操作的基本单位 C一致性 当事务提交后，或者当事务发生回滚后，数据库的完整性约束不能被破坏 I隔离性 一个事务在提交之前，对其他事务都是不可见的 D持久性 事务提交之后对数据的修改是持久性的 ","date":"2024-02-13","objectID":"/mysql_transaction/:0:1","tags":["Mysql"],"title":"Mysql事务","uri":"/mysql_transaction/"},{"categories":["Mysql"],"content":"事务语句 Start Transaction或者 begin, 显式的开启事务 Commit 提交事务 Rollback或者 Rollback to 回滚事务 Savepoint 在事务中创建保存点，方便后续针对保存点进行回滚 Release savepoint 删除某个保存点 Set transaction 设置事务的隔离级别 ","date":"2024-02-13","objectID":"/mysql_transaction/:0:2","tags":["Mysql"],"title":"Mysql事务","uri":"/mysql_transaction/"},{"categories":["Mysql"],"content":"设置自动提交 set autocommit = 0;//关闭 set autocommit = 1;//开启 ","date":"2024-02-13","objectID":"/mysql_transaction/:0:3","tags":["Mysql"],"title":"Mysql事务","uri":"/mysql_transaction/"},{"categories":["Mysql"],"content":"completion type参数 completion=0 当我们执行 commit的时候会提交事务，在执行下一个事务时，需要我们 start transaction或者 begin开启 completion=1 当我们提交事务后，相当执行了 commit and chain，开启一个链式事务。每条 SQL语句都会自动进行提交，如果采用start transaction或者begin显式开启事务，那么这个事务只有在 commit时才会生效，在 rollback时才会回滚 completion=2 commit and release 当我们提交事务后，会自动与服务器断开连接 ","date":"2024-02-13","objectID":"/mysql_transaction/:0:4","tags":["Mysql"],"title":"Mysql事务","uri":"/mysql_transaction/"},{"categories":["Mysql"],"content":"隔离性 脏读 读到了其他事务还没有提交的数据 可重复读 可重复读指的是在一个事务内，最开始读到的数据和事务结束前的任意时刻读到的同一批数据都是一致的。通常针对数据更新（UPDATE）操作。 不可重复读 在同一事务内，不同的时刻读到的同一批数据可能是不一样的，可能会受到其他事务的影响。通常针对数据更新（UPDATE）操作 幻读 幻读是针对数据插入（INSERT）操作来说的 ","date":"2024-02-13","objectID":"/mysql_transaction/:0:5","tags":["Mysql"],"title":"Mysql事务","uri":"/mysql_transaction/"},{"categories":["Mysql"],"content":"隔离级别 隔离级别 脏读 不可重复读 幻读 读未提交 可能 可能 可能 读提交 不可能 可能 可能 可重复读 不可能 不可能 可能 串行化 不可能 不可能 不可能 举例 事务 A 事务 B 启动事务，查询得到值 1 启动事务 查询得到值 1 将 1改成 2 查询得到值 V1 提交事务 B 查询得到值 V2 提交事务 A 查询得到值 V3 若隔离级别是“读未提交”，则 V1 的值就是 2。这时候事务 B 虽然还没有提交，但是结果已经被 A 看到了。因此，V2、V3 也都是 2。 若隔离级别是“读提交”，则 V1 是 1，V2 的值是 2。事务 B 的更新在提交后才能被 A看到。所以， V3 的值也是 2。 若隔离级别是“可重复读”，则 V1、V2 是 1，V3 是 2。之所以 V2 还是 1，遵循的就是这个要求：事务在执行期间看到的数据前后必须是一致的。 若隔离级别是“串行化”，则在事务 B 执行“将 1 改成 2”的时候，会被锁住。直到事务 A 提交后，事务 B 才可以继续执行。所以从 A 的角度看， V1、V2 值是 1，V3 的值是 2。 ","date":"2024-02-13","objectID":"/mysql_transaction/:0:6","tags":["Mysql"],"title":"Mysql事务","uri":"/mysql_transaction/"},{"categories":["Mysql"],"content":"快照在MVCC里是怎么工作的？ InnoDB 里面每个事务有一个唯一的事务 ID，叫作 transaction id。它是在事务开始的时候向 InnoDB 的事务系统申请的，是按申请顺序严格递增的。 而每行数据也都是有多个版本的。每次事务更新数据的时候，都会生成一个新的数据版本，并且把 transaction id 赋值给这个数据版本的事务 ID，记为 row trx_id。同时，旧的数据版本要保留，并且在新的数据版本中，能够有信息可以直接拿到它。 一个事务只需要在启动的时候声明说，“以我启动的时刻为准，如果一个数据版本是在我启动之前生成的，就认；如果是我启动以后才生成的，我就不认，我必须要找到它的上一个版本”。当然，如果“上一个版本”也不可见，那就得继续往前找。还有，如果是这个事务自己更新的数据，它自己还是要认的。 在实现上， InnoDB 为每个事务构造了一个数组，用来保存这个事务启动瞬间，当前正在“活跃”的所有事务 ID。“活跃”指的就是，启动了但还没提交。数组里面事务 ID 的最小值记为低水位，当前系统里面已经创建过的事务 ID 的最大值加 1记为高水位。 如果落在绿色部分，表示这个版本是已提交的事务或者是当前事务自己生成的，这个数据是可见的； 如果落在红色部分，表示这个版本是由将来启动的事务生成的，是肯定不可见的； 如果落在黄色部分，那就包括两种情况 a. 若 row trx_id 在数组中，表示这个版本是由还没提交的事务生成的，不可见； b. 若 row trx_id 不在数组中，表示这个版本是已经提交了的事务生成的，可见。 InnoDB 利用了“所有数据都有多个版本”的这个特性，实现了“秒级创建快照”的能力。 ","date":"2024-02-13","objectID":"/mysql_transaction/:0:7","tags":["Mysql"],"title":"Mysql事务","uri":"/mysql_transaction/"},{"categories":["Mysql"],"content":"更新逻辑 更新数据都是先读后写的，而这个读，只能读当前的值，称为“当前读”（current read）。 其实，除了 update 语句外，select 语句如果加锁（加上 lock inshare mode 或 for update），也是当前读。 事务的可重复读的能力是怎么实现的？ 核心就是一致性读（consistent read）；而事务更新数据的时候，只能用当前读。如果当前的记录的行锁被其他事务占用的话，就需要进入锁等待。 ","date":"2024-02-13","objectID":"/mysql_transaction/:0:8","tags":["Mysql"],"title":"Mysql事务","uri":"/mysql_transaction/"},{"categories":["Mysql"],"content":"为什么建议你尽量不要使用长事务？ 长事务意味着系统里面会存在很老的事务视图。由于这些事务随时可能访问数据库里面的任何数据，所以这个事务提交之前，数据库里面他可能用到的回滚记录都必须保留，这就会导致大量占用存储空间 ","date":"2024-02-13","objectID":"/mysql_transaction/:0:9","tags":["Mysql"],"title":"Mysql事务","uri":"/mysql_transaction/"},{"categories":["Mysql"],"content":"事务的启动方式 显式启动事物语句，begin或start transaction set autocommit=0，这个命令会将这个线程的自动提交关掉。 建议你总是使用 set autocommit=1, 通过显式语句的方式来启动事务。 在 information_schema 库的 innodb_trx 这个表中查询长事务。 ","date":"2024-02-13","objectID":"/mysql_transaction/:0:10","tags":["Mysql"],"title":"Mysql事务","uri":"/mysql_transaction/"},{"categories":["Mysql"],"content":"为保证数据库隔离级别的一致，将 MySQL 的隔离级别设置为“读提交” 配置的方式是，将启动参数 transaction-isolation 的值设置成 READ-COMMITTED。 show variables like ’transaction_isolation' ","date":"2024-02-13","objectID":"/mysql_transaction/:0:11","tags":["Mysql"],"title":"Mysql事务","uri":"/mysql_transaction/"},{"categories":["Go"],"content":"这篇文章展示了once用法","date":"2024-02-12","objectID":"/once/","tags":["Go"],"title":"once用法","uri":"/once/"},{"categories":["Go"],"content":"使用场景 once常常用来初始化单例资源，或者并发访问只需初始化一次的共享资源，或者在测试的时候初始化一次测试资源 ","date":"2024-02-12","objectID":"/once/:0:1","tags":["Go"],"title":"once用法","uri":"/once/"},{"categories":["Go"],"content":"实现 一个正确的once实现要使用一个互斥锁，这样初始化的时候如果有并发的goroutine，就会进入doSlow方法 ","date":"2024-02-12","objectID":"/once/:0:2","tags":["Go"],"title":"once用法","uri":"/once/"},{"categories":["Go"],"content":"2种错误 死锁 解决方案：不要在f参数中调用当前的这个once，不管是直接的还是间接的 未初始化 解决方案：可以自己实现一个类似once的并发原语，既可以以返回当前调用do方法是否正确完成，还可以在初始化失败后调用do方法再次尝试初始化，知道初始化成功才不再初始化了 ","date":"2024-02-12","objectID":"/once/:0:3","tags":["Go"],"title":"once用法","uri":"/once/"},{"categories":["Go"],"content":"这篇文章展示了random用法","date":"2024-02-12","objectID":"/rand/","tags":["Go"],"title":"random用法","uri":"/rand/"},{"categories":["Go"],"content":"golang生成随机数可以使用math/rand包 示例如下： package main import ( \"fmt\" \"math/rand\" ) func main() { for i:=0; i\u003c10; i++ { fmt.Println(rand.Intn(100)) } } 而发现这种情况,每次执行的结果一样. 修改如下： package main import ( \"fmt\" \"time\" \"math/rand\" ) func main() { r := rand.New(rand.NewSource(time.Now().UnixNano())) for i:=0; i\u003c10; i++ { fmt.Println(r.Intn(100)) } } 而这种方式就可以使用时间种子来获取不同的结果了。 示例2： package main import ( \"fmt\" \"math/rand\" \"time\" ) func main() { rand.Seed(time.Now().UnixNano()) for i := 0; i \u003c 10; i++ { x := rand.Intn(100) fmt.Println(x) } } 例子是打印10个100以内（0-99）的随机数字。 ","date":"2024-02-12","objectID":"/rand/:0:1","tags":["Go"],"title":"random用法","uri":"/rand/"},{"categories":["Mysql"],"content":"这篇文章展示了Mysql日志用法.","date":"2024-02-11","objectID":"/mysql_log/","tags":["Mysql"],"title":"Mysql日志","uri":"/mysql_log/"},{"categories":["Mysql"],"content":"binlog的写入机制 写入逻辑: 事务执行过程中，先把日志写到 binlog cache，事务提交的时候，再把 binlog cache 写到 binlog 文件中。 系统给 binlog cache 分配了一片内存，每个线程一个，参数 binlog_cache_size 用于控制单个线程内 binlog cache 所占内存的大小。如果超过了这个参数规定的大小，就要暂存到磁盘。 事务提交的时候，执行器把 binlog cache 里的完整事务写入到 binlog 中，并清空 binlogcache。 write 和 fsync 的时机，是由参数 sync_binlog 控制的： sync_binlog=0 的时候，表示每次提交事务都只 write，不 fsync； sync_binlog=1 的时候，表示每次提交事务都会执行 fsync； sync_binlog=N(N\u003e1) 的时候，表示每次提交事务都 write，但累积 N 个事务后才fsync。 因此，在出现 IO 瓶颈的场景里，将 sync_binlog 设置成一个比较大的值，可以提升性能。在实际的业务场景中，考虑到丢失日志量的可控性，一般不建议将这个参数设成 0，比较常见的是将其设置为 100~1000 中的某个数值。 但是，将 sync_binlog 设置为 N，对应的风险是：如果主机发生异常重启，会丢失最近 N个事务的 binlog 日志。 ","date":"2024-02-11","objectID":"/mysql_log/:1:0","tags":["Mysql"],"title":"Mysql日志","uri":"/mysql_log/"},{"categories":["Mysql"],"content":"Redo log的写入机制(Innodb特有) 当有一条记录需要更新的时候，InnoDB 引擎就会先把记录写到 redo log里面，并更新内存，这个时候更新就算完成了。同时，InnoDB 引擎会在适当的时候，将这个操作记录更新到磁盘里面，而这个更新往往是在系统比较空闲的时候做。 事务还没提交的时候，redo log buffer 中的部分日志有没有可能被持久化到磁盘呢？ 有。 为了控制 redo log 的写入策略，InnoDB 提供了 innodb_flush_log_at_trx_commit 参数，它有三种可能取值： 设置为 0 的时候，表示每次事务提交时都只是把 redo log 留在 redo log buffer 中 ; 设置为 1 的时候，表示每次事务提交时都将 redo log 直接持久化到磁盘（建议）； 设置为 2 的时候，表示每次事务提交时都只是把 redo log 写到 page cache。 除了后台线程每秒一次的轮询操作外，还有两种场景会让一个没有提交的事务的redo log 写入到磁盘中。 一种是，redo log buffer 占用的空间即将达到 innodb_log_buffer_size 一半的时候，后台线程会主动写盘。 另一种是，并行的事务提交的时候，顺带将这个事务的 redo log buffer 持久化到磁盘。 通常我们说 MySQL 的“双 1”配置，指的就是 sync_binlog 和innodb_flush_log_at_trx_commit 都设置成 1。也就是说，一个事务完整提交前，需要等待两次刷盘，一次是 redo log（prepare 阶段），一次是 binlog。 LSN是单调递增的，用来对应 redo log 的一个个写入点。每次写入长度为 length 的 redolog，LSN 的值就会加上 length。 WAL:write-Ahead Logging 先写日志，在写磁盘 WAL 机制主要得益于两个方面： redo log 和 binlog 都是顺序写，磁盘的顺序写比随机写速度要快； 组提交机制，可以大幅度降低磁盘的 IOPS 消耗。 如果你的 MySQL 现在出现了性能瓶颈，而且瓶颈在 IO 上，可以通过哪些方法来提升性能呢？ 设置 binlog_group_commit_sync_delay 和binlog_group_commit_sync_no_delay_count 参数，减少 binlog 的写盘次数。这个方法是基于“额外的故意等待”来实现的，因此可能会增加语句的响应时间，但没有丢失数据的风险。 将 sync_binlog 设置为大于 1 的值（比较常见是 100~1000）。这样做的风险是，主机掉电时会丢 binlog 日志。 将 innodb_flush_log_at_trx_commit 设置为 2。这样做的风险是，主机掉电的时候会丢数据。 ","date":"2024-02-11","objectID":"/mysql_log/:2:0","tags":["Mysql"],"title":"Mysql日志","uri":"/mysql_log/"},{"categories":["Mysql"],"content":"区别 redo log 是 InnoDB 引擎特有的；binlog 是 MySQL 的 Server 层实现的，所有引擎都可以使用。 redo log 是物理日志，记录的是“在某个数据页上做了什么修改”；binlog 是逻辑日志，记录的是这个语句的原始逻辑，比如“给 ID=2 这一行的 c 字段加 1 ”。 redo log 是循环写的，空间固定会用完；binlog 是可以追加写入的。“追加写”是指binlog 文件写到一定大小后会切换到下一个，并不会覆盖以前的日志。 ","date":"2024-02-11","objectID":"/mysql_log/:2:1","tags":["Mysql"],"title":"Mysql日志","uri":"/mysql_log/"},{"categories":["Mysql"],"content":"执行 Update更新流程 ","date":"2024-02-11","objectID":"/mysql_log/:2:2","tags":["Mysql"],"title":"Mysql日志","uri":"/mysql_log/"},{"categories":["Mysql"],"content":"这篇文章展示了Mysql锁.","date":"2024-02-11","objectID":"/mysql_lock/","tags":["Mysql"],"title":"Mysql锁","uri":"/mysql_lock/"},{"categories":["Mysql"],"content":"行锁功过：怎么减少行锁对性能的影响？ 从两阶段锁说起 在 InnoDB 事务中，行锁是在需要的时候才加上的，但并不是不需要了就立刻释放，而是要等到事务结束时才释放。这个就是两阶段锁协议。 死锁和死锁检测 当并发系统中不同线程出现循环资源依赖，涉及的线程都在等待别的线程释放资源时，就会导致这几个线程都进入无限等待的状态， 两种策略： 一种策略是，直接进入等待，直到超时。这个超时时间可以通过参数innodb_lock_wait_timeout 来设置。 另一种策略是，发起死锁检测，发现死锁后，主动回滚死锁链条中的某一个事务，让其他事务得以继续执行。将参数 innodb_deadlock_detect 设置为 on，表示开启这个逻辑。 一种头痛医头的方法，就是如果你能确保这个业务一定不会出现死锁，可以临时把死锁检测关掉。 另一个思路就是控制并发度 ","date":"2024-02-11","objectID":"/mysql_lock/:1:0","tags":["Mysql"],"title":"Mysql锁","uri":"/mysql_lock/"},{"categories":["Mysql"],"content":"全局锁和表锁：给表加个字段怎么有这么多阻碍？ ","date":"2024-02-11","objectID":"/mysql_lock/:2:0","tags":["Mysql"],"title":"Mysql锁","uri":"/mysql_lock/"},{"categories":["Mysql"],"content":"全局锁 命令： Flush tables with read lock (FTWRL) 使用场景：全库逻辑备份 逻辑备份工具： mysqldump。 当 mysqldump 使用参数–single-transaction的时候，导数据之前就会启动一个事务，来确保拿到一致性视图。 single-transaction 方法只适用于所有的表使用事务引擎的库。如果有的表使用了不支持事务的引擎，那么备份就只能通过 FTWRL 方法。 FTWRL与set global readonly=true区别： 在有些系统中，readonly 的值会被用来做其他逻辑，比如用来判断一个库是主库还是备库。因此，修改 global 变量的方式影响面更大，我不建议你使用。 在异常处理机制上有差异。如果执行 FTWRL 命令之后由于客户端发生异常断开，那么 MySQL 会自动释放这个全局锁，整个库回到可以正常更新的状态。而将整个库设置为 readonly 之后，如果客户端发生异常，则数据库就会一直保持 readonly 状态，这样会导致整个库长时间处于不可写状态，风险较高。 ","date":"2024-02-11","objectID":"/mysql_lock/:2:1","tags":["Mysql"],"title":"Mysql锁","uri":"/mysql_lock/"},{"categories":["Mysql"],"content":"表级锁 表锁： 语法： lock tables … read/write。 对于 InnoDB 这种支持行锁的引擎，一般不使用 lock tables 命令来控制并发，毕竟锁住整个表的影响面还是太大。 MDL(metadata lock)元数据锁 MDL 不需要显式使用，在访问一个表的时候会被自动加上。 读锁之间不互斥，因此你可以有多个线程同时对一张表增删改查。 读写锁之间、写锁之间是互斥的，用来保证变更表结构操作的安全性。 因此，如果有两个线程要同时给一个表加字段，其中一个要等另一个执行完才能开始执行。 如何安全的给小表加字段？ 解决长事务：在 MySQL 的information_schema 库的 innodb_trx 表中，你可以查到当前执行中的事务。如果你要做DDL 变更的表刚好有长事务在执行，要考虑先暂停 DDL，或者 kill 掉这个长事务。 如果你要变更的表是一个热点表，虽然数据量不大，但是上面的请求很频繁，而你不得不加个字段，你该怎么做呢？ 在 alter table语句里面设定等待时间，如果在这个指定的等待时间里面能够拿到 MDL 写锁最好，拿不到也不要阻塞后面的业务语句，先放弃。之后开发人员或者 DBA 再通过重试命令重复这个过程。 ","date":"2024-02-11","objectID":"/mysql_lock/:2:2","tags":["Mysql"],"title":"Mysql锁","uri":"/mysql_lock/"},{"categories":["Data"],"content":"这篇文章展示了数据结构.","date":"2024-02-11","objectID":"/struct/","tags":["Data"],"title":"数据结构","uri":"/struct/"},{"categories":["Data"],"content":"数组 数组是最常用的数据结构,创建数组必须要内存中一块连续的空间,并且数组中必须存放相同的数据类型 随机快速读写是数组的一个重要特性,但是要随机访问数据,必须知道数据在数组中的下标。如果我们只是知道数据的值,想要在数组中找到这个值,那么就只能遍历整个数组,时间复杂度为 O(N) ","date":"2024-02-11","objectID":"/struct/:0:1","tags":["Data"],"title":"数据结构","uri":"/struct/"},{"categories":["Data"],"content":"链表 链表可以使用零散的内存空间存储数据。 链表中的每个数据元素都必须包含一个指向下一个数据元素的内存地址指针。 因为链表是不连续存储的,要想在链表中查找一个数据,只能遍历链表,所以链表的查找复杂度总是 O(N)。 在链表中插入或者删除一个数据是非常容易的,只要找到要插入(删除)的位置,修改链表指针就可以了。 ","date":"2024-02-11","objectID":"/struct/:0:2","tags":["Data"],"title":"数据结构","uri":"/struct/"},{"categories":["Data"],"content":"栈 栈就是在线性表的基础上加了这样的操作限制条件:后面添加的数据,在删除的时候必须先删除,即通常所说的“后进先出” 栈在线性表的基础上增加了操作限制,具体实现的时候,因为栈不需要随机访问、也不需要在中间添加、删除数据,所以可以用数组实现,也可以用链表实现。 ","date":"2024-02-11","objectID":"/struct/:0:3","tags":["Data"],"title":"数据结构","uri":"/struct/"},{"categories":["Data"],"content":"hash表 Hash 表中数据以 Key、Value 的方式存储 Hash 表的物理存储其实是一个数组,如果我们能够根据 Key 计算出数组下标,那么就可以快速在数组中查找到需要的 Key 和 Value。 不同的 Key 有可能计算得到相同的数组下标,这就是所谓的 Hash 冲突,解决 Hash 冲突常用的方法是链表法。 因为数组要求存储固定数据类型,主要目的是每个数组元素中要存放固定长度的数据。 所以,数组中存储的是 Key、Value 数据元素的地址指针。一旦发生 Hash 冲突,只需要将相同下标,不同 Key 的数据元素添加到这个链表就可以了。查找的时候再遍历这个链表, 匹配正确的 Key。 ","date":"2024-02-11","objectID":"/struct/:0:4","tags":["Data"],"title":"数据结构","uri":"/struct/"},{"categories":["Data"],"content":"队列 队列是先进先出 ","date":"2024-02-11","objectID":"/struct/:0:5","tags":["Data"],"title":"数据结构","uri":"/struct/"},{"categories":["Data"],"content":"树 ","date":"2024-02-11","objectID":"/struct/:0:6","tags":["Data"],"title":"数据结构","uri":"/struct/"},{"categories":["Network"],"content":"这篇文章展示了程序运行状态.","date":"2024-02-10","objectID":"/programma_status/","tags":["Network"],"title":"程序运行状态","uri":"/programma_status/"},{"categories":["Network"],"content":"系统为什么会变慢,为什么会崩溃 当某些代码修改内存堆里的数据的时候,如果有多个线程在同时执行,就可能会出现同时修改数据的情况,比如,两个线程同时对一个堆中的数据执行 +1 操作,最终这个数据只会被加一次,这就是人们常说的线程安全问题 多个线程访问共享资源的这段代码被称为临界区,解决线程安全问题的主要方法是使用锁, 将临界区的代码加锁,只有获得锁的线程才能执行临界区代码 锁会引起线程阻塞,如果有很多线程同时在运行,那么就会出现线程排队等待锁的情况,线程无法并行执行,系统响应速度就会变慢。 被阻塞的线程越多,占据的系统资源也越多,这些被阻塞的线程既不能继续执行,也不能释放当前已经占据的资源,在系统中一边等待一边消耗资源,如果阻塞的线程数超过了某个系统资源的极限,就会导致系统宕机,应用崩溃。 解决系统因高并发而导致的响应变慢、应用崩溃的主要手段是使用分布式系统架构 此外必要时还需要在请求入口处进行限流,减小系统的并发请求数;在应用内进行业务降级,减小线程的资源消耗 ","date":"2024-02-10","objectID":"/programma_status/:0:1","tags":["Network"],"title":"程序运行状态","uri":"/programma_status/"},{"categories":["Network"],"content":"一台计算机如何同时处理数以百计的任务 主要依靠的是操作系统的 CPU 分时共享技术。如果同时有很多个进程在执行,操作系统会将 CPU 的执行时间分成很多份,进程按照某种策略轮流在 CPU 上运行。 在实际物理上,进程并不总是在 CPU 上运行的,一方面进程共享 CPU,所以需要等待 CPU 运行,另一方面,进程在执行 I/O 操作的时候,也不需要 CPU 运行。进程在生命周期中 运行:当一个进程在 CPU 上运行时,则称该进程处于运行状态。处于运行状态的进程的数目小于等于 CPU 的数目。 就绪:当一个进程获得了除 CPU 以外的一切所需资源,只要得到 CPU 即可运行,则称此进程处于就绪状态,就绪状态有时候也被称为等待运行状态。 阻塞:也称为等待或睡眠状态,当一个进程正在等待某一事件发生(例如等待 I/O 完成,等待锁……)而暂时停止运行,这时即使把 CPU 分配给进程也无法运行,故称该进程处于阻塞状态。 线程可以理解为轻量级的进程,在进程内创建,拥有自己的线程栈,在 CPU 上进行线程切换的代价也更小。线程在运行时, 和进程一样 ","date":"2024-02-10","objectID":"/programma_status/:0:2","tags":["Network"],"title":"程序运行状态","uri":"/programma_status/"},{"categories":["Network"],"content":"程序是如何运行起来的 不管是文本格式的代码还是可执行的代码,都被称为程序 要想让程序处理数据,完成计算任务,必须把程序从外部设备加载到内存中, 并在操作系统的管理调度下交给 CPU 去执行,去运行起来,才能真正发挥软件的作用,程序运行起来以后,被称作进程。 操作系统把可执行代码加载到内存中,生成相应的数据结构和内存空间后,就从可执行代码的起始位置读取指令交给 CPU 顺序执行。指令执行过程中,可能会遇到一条跳转指令,即 CPU 要执行的下一条指令不是内存中可执行代码顺序的下一条指令。 img.png 程序运行时如果需要创建数组等数据结构，操作系统就会在进程的堆空间申请一块相应的内存空间，并把这块的内存的首地址信息记录在进程的栈中 栈是严格的一个后进先出的数据结构，同样由操作系统维护，主要用来记录函数内部的局部变量、堆空间分配的内存空间地址等 ","date":"2024-02-10","objectID":"/programma_status/:0:3","tags":["Network"],"title":"程序运行状态","uri":"/programma_status/"},{"categories":["Network"],"content":"进程与线程 并发不是并行。并行是指两个或多个线程同时在不同的处理器执行代码 空的select语句将永远阻塞 当不知道什么时候结束时，不要开启goroutine 异步执行函数的决定权交给该函数的调用方 ","date":"2024-02-10","objectID":"/programma_status/:0:4","tags":["Network"],"title":"程序运行状态","uri":"/programma_status/"},{"categories":["Network"],"content":"这篇文章展示了网络编程.","date":"2024-02-10","objectID":"/programma/","tags":["Network"],"title":"网络编程","uri":"/programma/"},{"categories":["Network"],"content":"DNS 构成互联网 Internet 的最基本的网络协议就是互联网协议 InternetProtocol,简称 IP 协议。 事实上这个 IP 地址是通过 DNS 域名解析服务器得到的。 ","date":"2024-02-10","objectID":"/programma/:0:1","tags":["Network"],"title":"网络编程","uri":"/programma/"},{"categories":["Network"],"content":"CDN CDN 是内容分发网络 Content Delivery Network 的缩写。我们能够用手机或者电脑上网,是因为运营服务商为我们提供了互联网接入服务,将我们的手机和电脑连接到互联网上。 ","date":"2024-02-10","objectID":"/programma/:0:2","tags":["Network"],"title":"网络编程","uri":"/programma/"},{"categories":["Network"],"content":"HTTP HTTP 是一个应用层协议 在 TCP 传输层协议层面,就是保证建立通信两方的稳定通信连接,将一方的数据以 bit 流的方式源源不断地发送到另一方,至于这些数据代表什么意思,哪里是两次请求的分界点, TCP 协议统统不管,需要应用层面自己解决 状态码是 200,表示响应正常 响应状态码: 3XX,表示请求被重定向,常用的 302,表示请求被临时重定向到新的 URL,响应头中包含新的临时 URL,客户端收到响应后,重新请求这个新的 URL 4XX,表示客户端错误,常见的 403,表示请求未授权,被禁止访问,404 表示请求的页面不存在 5XX,表示服务器异常,常见的 500 请求未完成,502 请求处理超时,503 服务器过载 ","date":"2024-02-10","objectID":"/programma/:0:3","tags":["Network"],"title":"网络编程","uri":"/programma/"},{"categories":["Network"],"content":"TCP TCP 仅仅是一个传输层协议 物理层负责数据的物理传输 数据链路层就是将数据进行封装后交给物理层进行传输,主要就是将数据封装成数据帧,以帧为单位通过物理层进行通信,有了帧,就可以在帧上进行数据校验,进行流量控制 一台机器可能同时有很多进程在进行网络通信。如何使数据到达服务器后能发送给正确的进程去处理,就需要靠通信端口进行标识了 ","date":"2024-02-10","objectID":"/programma/:0:4","tags":["Network"],"title":"网络编程","uri":"/programma/"},{"categories":["Network"],"content":"LB 搜索请求到达数据中心的时候,首先到达的是搜索服务器集群的负载均衡服务器,也就是说,DNS 解析出来的是负载均衡服务器的 IP 地址。然后,由负载均衡服务器将请求分发到搜索服务器集群中的某台服务器上 ","date":"2024-02-10","objectID":"/programma/:0:5","tags":["Network"],"title":"网络编程","uri":"/programma/"},{"categories":["File"],"content":"这篇文章展示了文件系统相关知识.","date":"2024-02-09","objectID":"/system/","tags":["File"],"title":"文件系统","uri":"/system/"},{"categories":["File"],"content":"硬盘 硬盘是一种可持久保存、多次读写数据的存储介质 机械式硬盘的数据就存储在具有磁性特质的盘片上,因此这种硬盘也被称为磁盘 固态硬盘则没有这种磁性特质的存储介质,也没有电机驱动的机械式结构 ","date":"2024-02-09","objectID":"/system/:0:1","tags":["File"],"title":"文件系统","uri":"/system/"},{"categories":["File"],"content":"文件系统 inode 中记录着文件权限、所有者、修改时间和文件大小等文件属性信息,以及文件数据块硬盘地址索引。inode 是固定结构的,能够记录的硬盘地址索引数也是固定的,只有 15 个索引。其中前 12 个索引直接记录数据块地址,第 13 个索引记录索引地址,也就是说, 索引块指向的硬盘数据块并不直接记录文件数据,而是记录文件数据块的索引表,每个索引表可以记录 256 个索引;第 14 个索引记录二级索引地址,第 15 个索引记录三级索引地址 ","date":"2024-02-09","objectID":"/system/:0:2","tags":["File"],"title":"文件系统","uri":"/system/"},{"categories":["File"],"content":"RAID RAID,即独立硬盘冗余阵列,将多块硬盘通过硬件 RAID 卡或者软件 RAID 的方案管理起来,使其共同对外提供服务。 常用 RAID 有五种,分别是 RAID 0、RAID 1、RAID 10、RAID 5 和 RAID 6。 ","date":"2024-02-09","objectID":"/system/:0:3","tags":["File"],"title":"文件系统","uri":"/system/"},{"categories":["File"],"content":"分布式文件系统 DataNode 负责文件数据的存储和读写操作,HDFS 将文件数据分割成若干数据块(Block),每个 DataNode 存储一部分数据块,这样文件就分布存储在整个 HDFS 服务器集群中。 NameNode 负责整个分布式文件系统的元数据(MetaData)管理,也就是文件路径名、访问权限、数据块的 ID 以及存储位置等信息,相当于 Linux 系统中 inode 的角色。HDFS 为了保证数据的高可用,会将一个数据块复制为多份(缺省情况为3份),并将多份相同的数据块存储在不同的服务器上,甚至不同的机架上。这样当有硬盘损坏,或者某个 DataNode 服务器宕机,甚至某个交换机宕机,导致其存储的数据块不能访问的时候,客户端会查找其备份的数据块进行访问。 DFS为了保证数据的高可用,会将一个数据块复制为多份(缺省情况为3份),并将多份相同的数据块存储在不同的服务器上,甚至不同的机架上。这样当有硬盘损坏,或者某个DataNode服务器宕机,甚至某个交换机宕机,导致其存储的数据块不能访问的时候,客户端会查找其备份的数据块进行访问。 ","date":"2024-02-09","objectID":"/system/:0:4","tags":["File"],"title":"文件系统","uri":"/system/"},{"categories":["Mysql"],"content":"这篇文章展示了Mysql Scheme内容.","date":"2024-02-08","objectID":"/mysql_scheme/","tags":["Mysql"],"title":"Mysql Scheme","uri":"/mysql_scheme/"},{"categories":["Mysql"],"content":"选择优化的数据类型 字符串类型 VARCHAR类型用于存储可变长的字符串，所以它需要1或2个额外的字节记录字符串的长度：如果列的长度小于或等于255个字节，则只使用1个字节表示，否则使用2个字节表示。例如varchar(10)就需要11个字节，varchar(1000)则需要1002个字节。 VARCHAR节省了存储空间，所以对性能有所帮助。但由于行是变长的，在UPDATE时可能是原来的行更长，这就会导致需要做一些额外的工作。如果一个行占用的空间曾长，并且在页内没有更多的空间可以存储，这是INNODB就会分裂当前页来使行可以放进页内。 下面这些情况使用VARCHAR是合适的： 字符串列的最大长度比平均长度大很多 列的更新很少 使用了UTF-8这样的字符集，每个字符都是用不同的字节存储 CHAR类型是定长的：MySQL总是根据定义字符串的长度分配足够空间。因为CHAR会根据需要采用空格填充到字符串末尾，而且当你检索时，CHAR会删除末尾的空格。所以会有一个很有趣的事情发生，当你存储一个\"Johnson “到char(10)时，检索出来的结果却是\"Johnson”，因为MySQL并不知道这空格是你存的还是系统自动填充的。 CHAR很适合存储很短的字符串或所有值都接近同一个长度。例如密码的MD5值。 BLOB和TEXT都是为了存储很大的数据类型而设计的字符串数据类型，分别采用二进制和字符方式存储。而且当它们存储的数据过大时，INNOSB会使用专门的‘外部’空间来存储数据，此时每个值的行内仅存储一个1 ～ 4个字节的指针，然后在外部区域存储真实的指。当需要对BLOB和TEXT排序时，它只对每个列的最前 max_sort_length 进行排序。这个值是可以配置的。 ","date":"2024-02-08","objectID":"/mysql_scheme/:0:1","tags":["Mysql"],"title":"Mysql Scheme","uri":"/mysql_scheme/"},{"categories":["Design"],"content":"这篇文章展示了软件建模基本知识.","date":"2024-01-14","objectID":"/modeling/","tags":["Design"],"title":"软件建模","uri":"/modeling/"},{"categories":["Design"],"content":"软件建模 模型是对客观存在的抽象 抽象表达事务的本质规律 把握事物的本质规律和主要特征,正确建造模型和使用模型,以防在各种细节中迷失方向。 一个是我们要解决的领域问题 另一个客观存在就是最终开发出来的软件系统 ","date":"2024-01-14","objectID":"/modeling/:1:0","tags":["Design"],"title":"软件建模","uri":"/modeling/"},{"categories":["Design"],"content":"4+1视图模型 逻辑视图 描述软件的功能逻辑,由哪些模块组成,模块中包含那些类,其依赖关系如何。 开发视图 包括系统架构层面的层次划分,包的管理,依赖的系统与第三方的程序包。 开发视图某些方面和逻辑视图有一定重复性,不同视角看到的可能是同一个东西,开发视图中一个程序包,可能正好对应逻辑视图中的一个功能模块。 过程视图 描述程序运行期的进程、线程、对象实例,以及与此相关的并发、同步、通信等问题。 物理视图 描述软件如何安装并部署到物理的服务上,以及不同的服务器之间如何关联、通信。 场景视图 针对具体的用例场景,将上述 4 个视图关联起来,一方面从业务角度描述, 功能流程如何完成,一方面从软件角度描述,相关组成部分如何互相依赖、调用。 ","date":"2024-01-14","objectID":"/modeling/:2:0","tags":["Design"],"title":"软件建模","uri":"/modeling/"},{"categories":["Design"],"content":"UML建模 一方面满足设计阶段和各个相关方沟通的目的;一方面可以用来思考,即使软件开发过程不需要跟其他人沟通,或者还没到沟通的时候,依然可以使用 UML 建模画图,帮助自己进行设计思考。 ","date":"2024-01-14","objectID":"/modeling/:3:0","tags":["Design"],"title":"软件建模","uri":"/modeling/"},{"categories":["Design"],"content":"这篇文章展示了软件设计文档基本知识.","date":"2024-01-13","objectID":"/doc/","tags":["Design"],"title":"软件设计文档","uri":"/doc/"},{"categories":["Design"],"content":"类图 类之间有 6 种静态关系:关联、依赖、组合、聚合、继承、泛化。 ","date":"2024-01-13","objectID":"/doc/:1:0","tags":["Design"],"title":"软件设计文档","uri":"/doc/"},{"categories":["Design"],"content":"序列图 序列图则用来描述参与者之间的动态调用关系。 ","date":"2024-01-13","objectID":"/doc/:2:0","tags":["Design"],"title":"软件设计文档","uri":"/doc/"},{"categories":["Design"],"content":"组件图 一方面满足设计阶段和各个相关方沟通的目的;一方面可以用来思考,即使软件开发过程不需要跟其他人沟通,或者还没到沟通的时候,依然可以使用 UML 建模画图,帮助自己进行设计思考。 ","date":"2024-01-13","objectID":"/doc/:3:0","tags":["Design"],"title":"软件设计文档","uri":"/doc/"},{"categories":["Design"],"content":"部署图 ","date":"2024-01-13","objectID":"/doc/:4:0","tags":["Design"],"title":"软件设计文档","uri":"/doc/"},{"categories":["Design"],"content":"用例图 用例图主要用在需求分析阶段,通过反映用户和软件系统的交互,描述系统的功能需求 ","date":"2024-01-13","objectID":"/doc/:5:0","tags":["Design"],"title":"软件设计文档","uri":"/doc/"},{"categories":["Design"],"content":"状态图 状态图用来展示单个对象生命周期的状态变迁 ","date":"2024-01-13","objectID":"/doc/:6:0","tags":["Design"],"title":"软件设计文档","uri":"/doc/"},{"categories":["Design"],"content":"活动图 活动图主要用来描述过程逻辑和业务流程。 ","date":"2024-01-13","objectID":"/doc/:7:0","tags":["Design"],"title":"软件设计文档","uri":"/doc/"},{"categories":["Go"],"content":"这篇文章展示了channel用法","date":"2024-01-12","objectID":"/channel/","tags":["Go"],"title":"channel用法","uri":"/channel/"},{"categories":["Go"],"content":"CSP 允许使用进程组件来描述系统，它们独立运行，并且只通过消息传递的方式通信 ","date":"2024-01-12","objectID":"/channel/:0:0","tags":["Go"],"title":"channel用法","uri":"/channel/"},{"categories":["Go"],"content":"channel的应用场景 执行业务处理的 goroutine 不要通过共享内存的方式通信，而是要通过 Channel 通信的方式分享数据 五种类型： 数据交流 数据传递 信号通知 任务编排 锁 ","date":"2024-01-12","objectID":"/channel/:0:1","tags":["Go"],"title":"channel用法","uri":"/channel/"},{"categories":["Go"],"content":"channel的基本用法 只能接收、只能发送、既可以接收又可以发送三种类型 发送数据 ch \u003c- 2000 接收数据 x := \u003c-ch //把接收的一条数据赋值给变量x foo(\u003c-ch) //把接收的一个数据作为参数传给函数 \u003c-ch //丢弃接收的一条数据 其他操作 send和recv都可以作为select语句的case clause 可以用于for-range语句中 ","date":"2024-01-12","objectID":"/channel/:0:2","tags":["Go"],"title":"channel用法","uri":"/channel/"},{"categories":["Go"],"content":"实现原理 数据结构 qcount：代表 chan 中已经接收但还没被取走的元素的个数。内建函数 len 可以返回这个字段的值。 dataqsiz：队列的大小。chan 使用一个循环队列来存放元素，循环队列很适合这种生产者 - 消费者的场景（我很好奇为什么这个字段省略 size 中的 e）。 buf：存放元素的循环队列的 buffer。 elemtype 和 elemsize：chan 中元素的类型和 size。因为 chan 一旦声明，它的元素类型是固定的，即普通类型或者指针类型，所以元素大小也是固定的 sendx：处理发送数据的指针在 buf 中的位置。一旦接收了新的数据，指针就会加上elemsize，移向下一个位置。buf 的总大小是 elemsize 的整数倍，而且 buf 是一个循环列表。 recvx：处理接收请求时的指针在 buf 中的位置。一旦取出数据，此指针会移动到下一个位置。 recvq：chan 是多生产者多消费者的模式，如果消费者因为没有数据可读而被阻塞了，就会被加入到 recvq 队列中。 sendq：如果生产者因为 buf 满了而阻塞，会被加入到 sendq 队列 初始化 Go 在编译的时候，会根据容量的大小选择调用 makechan64，还是 makechan。 我们只关注 makechan 就好了，因为 makechan64 只是做了 size 检查，底层还是调用makechan 实现的。makechan 的目标就是生成 hchan 对象。 send Go 在编译发送数据给 chan 的时候，会把 send 语句转换成 chansend1 函数，chansend1 函数会调用 chansend recv 在处理从 chan 中接收数据时，Go 会把代码转换成 chanrecv1 函数，如果要返回两个返回值，会转换成 chanrecv2，chanrecv1 函数和 chanrecv2 会调用 chanrecv。 close 通过 close 函数，可以把 chan 关闭，编译器会替换成 closechan 方法的调用 ","date":"2024-01-12","objectID":"/channel/:0:3","tags":["Go"],"title":"channel用法","uri":"/channel/"},{"categories":["Go"],"content":"容易犯的错误 常见panic close 为 nil 的 chan； send 已经 close 的 chan； close 已经 close 的 chan goroutine泄漏： func process(timeout time.Duration) bool { ch := make(chan bool) go func() { // 模拟处理耗时的业务 time.Sleep((timeout + time.Second)) ch \u003c- true // block fmt.Println(\"exit goroutine\") }() select { case result := \u003c-ch: return result case \u003c-time.After(timeout): return false } } 在这个例子中，process 函数会启动一个 goroutine，去处理需要长时间处理的业务，处理完之后，会发送 true 到 chan 中，目的是通知其它等待的 goroutine，可以继续处理了。 我们来看一下第 10 行到第 15 行，主 goroutine 接收到任务处理完成的通知，或者超时后就返回了。这段代码有问题吗？ 如果发生超时，process 函数就返回了，这就会导致 unbuffered 的 chan 从来就没有被读取。我们知道，unbuffered chan 必须等 reader 和 writer 都准备好了才能交流，否则就会阻塞。超时导致未读，结果就是子 goroutine 就阻塞在第 7 行永远结束不了，进而导致 goroutine 泄漏。 解决这个 Bug 的办法很简单，就是将 unbuffered chan 改成容量为 1 的 chan，这样第 7 行就不会被阻塞了。 ","date":"2024-01-12","objectID":"/channel/:0:4","tags":["Go"],"title":"channel用法","uri":"/channel/"},{"categories":["Go"],"content":"选择方法 共享资源的并发访问使用传统并发原语； 复杂的任务编排和消息传递使用 Channel； 消息通知机制使用 Channel，除非只想 signal 一个 goroutine，才使用 Cond 简单等待所有任务的完成用 WaitGroup，也有 Channel 的推崇者用 Channel，都可以； 需要和 Select 语句结合，使用 Channel； 需要和超时配合时，使用 Channel 和 Context。 nil empty full not full\u0026empty closed receive block block read value read value 返回未读的元素，读完后返回零值 send block write value block write value panic closed panic closed,没有未读元素 closed,保留未读元素 closed,保留未读元素 panic ","date":"2024-01-12","objectID":"/channel/:0:5","tags":["Go"],"title":"channel用法","uri":"/channel/"},{"categories":["Go"],"content":"这篇文章展示了cond用法","date":"2024-01-12","objectID":"/cond/","tags":["Go"],"title":"cond用法","uri":"/cond/"},{"categories":["Go"],"content":"go标准库cond cond通常应用于等待某个条件一组gorotine，等条件变为true的时候，其中一个goroutine或者所有goroutine都会被唤醒执行 ","date":"2024-01-12","objectID":"/cond/:1:0","tags":["Go"],"title":"cond用法","uri":"/cond/"},{"categories":["Go"],"content":"cond的基本用法 ","date":"2024-01-12","objectID":"/cond/:2:0","tags":["Go"],"title":"cond用法","uri":"/cond/"},{"categories":["Go"],"content":"signal 允许调用者caller唤醒一个等待此cond的goroutine ","date":"2024-01-12","objectID":"/cond/:2:1","tags":["Go"],"title":"cond用法","uri":"/cond/"},{"categories":["Go"],"content":"broadcase 允许调用者caller唤醒所有等待此cond的goroutine ","date":"2024-01-12","objectID":"/cond/:2:2","tags":["Go"],"title":"cond用法","uri":"/cond/"},{"categories":["Go"],"content":"wait 会把调用者caller放入cond的等待队列中并阻塞，直到被signal或者broadcast的方法从等待队列中移除并唤醒 ","date":"2024-01-12","objectID":"/cond/:2:3","tags":["Go"],"title":"cond用法","uri":"/cond/"},{"categories":["Go"],"content":"使用cond的2个常见错误 调用wait的时候没有加锁 只调用了一次wait，没有检查等待条件是否满足，结果条件没满足。程序就继续执行 ","date":"2024-01-12","objectID":"/cond/:3:0","tags":["Go"],"title":"cond用法","uri":"/cond/"},{"categories":["Go"],"content":"知名项目中cond的使用 ","date":"2024-01-12","objectID":"/cond/:4:0","tags":["Go"],"title":"cond用法","uri":"/cond/"},{"categories":["Go"],"content":"K8s 定义了优先队列PriorityQueue这样一个数据结构，用来实现pod的调用 ","date":"2024-01-12","objectID":"/cond/:4:1","tags":["Go"],"title":"cond用法","uri":"/cond/"},{"categories":["Go"],"content":"cond有3点特性，是channel无法替代的 cond和一个locker关联，可以利用这个locker对相关的依赖条件更改提供保护 cond可以同时支持signal和broadcast方法，而channel只能同时支持其中一个 cond的broadcast方法可以被重复调用 ","date":"2024-01-12","objectID":"/cond/:4:2","tags":["Go"],"title":"cond用法","uri":"/cond/"},{"categories":["Go"],"content":"使用案例 var done = false func read(name string, c *sync.Cond) { c.L.Lock() for !done { c.Wait() } log.Println(name, \"starts reading\") c.L.Unlock() } func write(name string, c *sync.Cond) { log.Println(name, \"starts writing\") time.Sleep(time.Second) c.L.Lock() done = true c.L.Unlock() log.Println(name, \"wakes all\") c.Broadcast() } func main() { cond := sync.NewCond(\u0026sync.Mutex{}) go read(\"reader1\", cond) go read(\"reader2\", cond) go read(\"reader3\", cond) write(\"writer\", cond) time.Sleep(time.Second * 3) } ","date":"2024-01-12","objectID":"/cond/:5:0","tags":["Go"],"title":"cond用法","uri":"/cond/"},{"categories":["Go"],"content":"这篇文章展示了context用法","date":"2024-01-12","objectID":"/context/","tags":["Go"],"title":"context用法","uri":"/context/"},{"categories":["Go"],"content":"来历 Go在1.7的版本中才正式把context加入到标准库中 ","date":"2024-01-12","objectID":"/context/:1:0","tags":["Go"],"title":"context用法","uri":"/context/"},{"categories":["Go"],"content":"适用场景 ","date":"2024-01-12","objectID":"/context/:2:0","tags":["Go"],"title":"context用法","uri":"/context/"},{"categories":["Go"],"content":"上下文信息传递 ","date":"2024-01-12","objectID":"/context/:2:1","tags":["Go"],"title":"context用法","uri":"/context/"},{"categories":["Go"],"content":"控制子goroutine的运行 ","date":"2024-01-12","objectID":"/context/:2:2","tags":["Go"],"title":"context用法","uri":"/context/"},{"categories":["Go"],"content":"超时控制 ","date":"2024-01-12","objectID":"/context/:2:3","tags":["Go"],"title":"context用法","uri":"/context/"},{"categories":["Go"],"content":"可以取消的方法调用 ","date":"2024-01-12","objectID":"/context/:2:4","tags":["Go"],"title":"context用法","uri":"/context/"},{"categories":["Go"],"content":"基本使用方法 ","date":"2024-01-12","objectID":"/context/:3:0","tags":["Go"],"title":"context用法","uri":"/context/"},{"categories":["Go"],"content":"4个实现方法 deadline方法：会返回这个context会被取消的截止日期 done方法：返回一个channel对象 Err:如果done没有close，Err方法返回nil；如果done被close,Err会返回done被close的原因 value返回此ctx中和制定的key相关联的value ","date":"2024-01-12","objectID":"/context/:3:1","tags":["Go"],"title":"context用法","uri":"/context/"},{"categories":["Go"],"content":"常用的生成顶层context的方法 Context.Backgroud():返回一个非nil、空的Context，没有任何之，不会被cancel,不会超时，没有截止日期 Context.TODO()：返回一个非nil、空的context，没有任何值，不会被cancel，不会超时，没有截止日期 ","date":"2024-01-12","objectID":"/context/:3:2","tags":["Go"],"title":"context用法","uri":"/context/"},{"categories":["Go"],"content":"适用规则 一般函数使用context的时候，会把这个参数放在第一个参数的位置 从来不把nil当作context类型的参数值，可以使用context.Backgroud()创建一个空的上下文对象，也不要使用nil context只用来临时做函数之间的上下文透传，不能持久化context或者context长久保存 key的类型不应该使用字符串类型或者其他内建类型，否则容易在包之间使用context时候冲突 常常使用struct{}作为底层类型定义key的类型 ","date":"2024-01-12","objectID":"/context/:3:3","tags":["Go"],"title":"context用法","uri":"/context/"},{"categories":["Go"],"content":"创建特殊用途context的方法 WithValue:基于parent context生成一个新的context，保存了一个key-value简直对，常常用来传递上下文 WithCancel:返回parent的副本，只是副本中的done channel是新建的对象，他的类型是cancelCtx WithTimeout:其实和WithDeadline一样，只不过一个参数是超时时间，一个参数是截止时间 WithDeadline：返回一个parent的副本，并且设置了一个不晚于参数d的截止时间，类型为timeCtx ","date":"2024-01-12","objectID":"/context/:4:0","tags":["Go"],"title":"context用法","uri":"/context/"},{"categories":["Go"],"content":"这篇文章展示了map用法","date":"2024-01-12","objectID":"/map/","tags":["Go"],"title":"map用法","uri":"/map/"},{"categories":["Go"],"content":"go内建的map类型 map的类型是map[key] key类型的k必须是可比较的 map[key]函数返回结果可以是一个值，也可以是两个值 map是无序的，想要保证遍历mao时元素有序，可以使用orderedmap ","date":"2024-01-12","objectID":"/map/:0:1","tags":["Go"],"title":"map用法","uri":"/map/"},{"categories":["Go"],"content":"使用map的2种常见错误 常见错误一：未初始化 常见错误二：并发读写 ","date":"2024-01-12","objectID":"/map/:0:2","tags":["Go"],"title":"map用法","uri":"/map/"},{"categories":["Go"],"content":"如何实现线程安全的map类型 加读写锁:扩展map,支持并发读写 分片加锁：更高效的并发map getShard是一个关键的方法，能够根据key计算出分片索引 ","date":"2024-01-12","objectID":"/map/:0:3","tags":["Go"],"title":"map用法","uri":"/map/"},{"categories":["Go"],"content":"应对特殊场景的sync.map 应用场景不多 设计与实现 store方法 load方法 delete方法 loadAndDelete方法 loadOrStore方法 range方法 实现优化点 空间换时间 优先从read字段读取，更新，删除 动态调整 double-checking 延迟删除 ","date":"2024-01-12","objectID":"/map/:0:4","tags":["Go"],"title":"map用法","uri":"/map/"},{"categories":["Go"],"content":"这篇文章展示了mutex用法","date":"2024-01-12","objectID":"/mutex/","tags":["Go"],"title":"mutex用法","uri":"/mutex/"},{"categories":["Go"],"content":"互斥锁的实现机制 在并发编程中，如果程序中的一部分会被并发访问或修改，那么，为了避免并发访问导致的意想不到的结果，这部分程序需要被保护起来，这部分被保护起来的程序，就叫做临界区 使用互斥锁，限定临界区只能同时由一个线程持有 ","date":"2024-01-12","objectID":"/mutex/:1:0","tags":["Go"],"title":"mutex用法","uri":"/mutex/"},{"categories":["Go"],"content":"适用场景： 共享资源。并发地读写共享资源，会出现数据竞争（data race）的问题，所以需要Mutex、RWMutex 这样的并发原语来保护。 ","date":"2024-01-12","objectID":"/mutex/:1:1","tags":["Go"],"title":"mutex用法","uri":"/mutex/"},{"categories":["Go"],"content":"Mutex的基本使用方法 互斥锁 Mutex 就提供两个方法 Lock 和 Unlock：进入临界区之前调用 Lock方法，退出临界区的时候调用 Unlock 方法 当一个 goroutine 通过调用 Lock 方法获得了这个锁的拥有权后，其它请求锁的goroutine 就会阻塞在 Lock 方法的调用上，直到锁被释放并且自己获取到了这个锁的拥有权。 Go race detector是基于 Google 的 C/C++ sanitizers 技术实现的，编译器通过探测所有的内存访问，加入代码能监视对这些内存地址的访问（读还是写）。在代码运行的时候，race detector 就能监控到对共享变量的非同步访问，出现 race 的时候，就会打印出警告信息 ","date":"2024-01-12","objectID":"/mutex/:2:0","tags":["Go"],"title":"mutex用法","uri":"/mutex/"},{"categories":["Go"],"content":"基本用法 func main() { var mu sync.Mutex var count = 0 var wg sync.WaitGroup wg.Add(10) for i := 0; i \u003c 10; i++ { go func() { defer wg.Done() for j := 0; j \u003c 100000; j++ { mu.Lock() count++ mu.Unlock() } }() } wg.Wait() fmt.Println(count) } 很多情况下，Mutex 会嵌入到其它 struct 中使用 package main import ( \"fmt\" \"sync\" ) type Counter struct { CounterType int Name string mu sync.Mutex count uint64 } func (c *Counter) Incr() { c.mu.Lock() c.count++ c.mu.Unlock() } func (c *Counter) Count() uint64 { c.mu.Lock() defer c.mu.Unlock() return c.count } func main() { var counter Counter var wg sync.WaitGroup wg.Add(10) for i := 0; i \u003c 10; i++ { go func() { defer wg.Done() for j := 0; j \u003c 100000; j++ { counter.Incr() } }() } wg.Wait() fmt.Println(counter.Count()) } ","date":"2024-01-12","objectID":"/mutex/:3:0","tags":["Go"],"title":"mutex用法","uri":"/mutex/"},{"categories":["Go"],"content":"演进之路 ","date":"2024-01-12","objectID":"/mutex/:4:0","tags":["Go"],"title":"mutex用法","uri":"/mutex/"},{"categories":["Go"],"content":"初版的互斥锁 Unlock 方法可以被任意的 goroutine 调用释放锁，即使是没持有这个互斥锁的goroutine，也可以进行这个操作。这是因为，Mutex 本身并没有包含持有这把锁的goroutine 的信息，所以，Unlock 也不会对此进行检查。Mutex 的这个设计一直保持至今 mutex包含两个字段： 字段key 字段sema 初版的 Mutex 实现有一个问题： 请求锁的 goroutine 会排队等待获取互斥锁。虽然这貌似很公平，但是从性能上来看，却不是最优的 ","date":"2024-01-12","objectID":"/mutex/:4:1","tags":["Go"],"title":"mutex用法","uri":"/mutex/"},{"categories":["Go"],"content":"给新人机会 第一个字段改成了state 相对于初版的设计，这次的改动主要就是，新来的 goroutine 也有机会先获取到锁，甚至一个 goroutine 可能连续获取到锁，打破了先来先得的逻辑。但是，代码复杂度也显而易见 ","date":"2024-01-12","objectID":"/mutex/:4:2","tags":["Go"],"title":"mutex用法","uri":"/mutex/"},{"categories":["Go"],"content":"多给些机会 如果新来的 goroutine 或者是被唤醒的 goroutine 首次获取不到锁，它们就会通过自旋（spin，通过循环不断尝试，spin 的逻辑是在runtime 实现的）的方式，尝试检查锁是否被释放。在尝试一定的自旋次数后，再执行原来的逻辑 ","date":"2024-01-12","objectID":"/mutex/:4:3","tags":["Go"],"title":"mutex用法","uri":"/mutex/"},{"categories":["Go"],"content":"解决饥饿 只需要记住，Mutex 绝不容忍一个goroutine 被落下，永远没有机会获取锁。不抛弃不放弃是它的宗旨，而且它也尽可能地让等待较长的 goroutine 更有机会获取到锁 跟之前的实现相比，当前的 Mutex 最重要的变化，就是增加饥饿模式。第 12 行将饥饿模式的最大等待时间阈值设置成了 1 毫秒，这就意味着，一旦等待者等待的时间超过了这个阈值，Mutex 的处理就有可能进入饥饿模式，优先让等待者先获取到锁 饥饿模式和正常模式 正常模式下，waiter 都是进入先入先出队列，被唤醒的 waiter 并不会直接持有锁，而是要和新来的 goroutine 进行竞争。新来的 goroutine 有先天的优势，它们正在 CPU 中运行，可能它们的数量还不少，所以，在高并发情况下，被唤醒的 waiter 可能比较悲剧地获取不到锁，这时，它会被插入到队列的前面。如果 waiter 获取不到锁的时间超过阈值 1 毫秒，那么，这个 Mutex 就进入到了饥饿模式。 在饥饿模式下，Mutex 的拥有者将直接把锁交给队列最前面的 waiter。新来的 goroutine不会尝试获取锁，即使看起来锁没有被持有，它也不会去抢，也不会 spin，它会乖乖地加入到等待队列的尾部。 如果拥有 Mutex 的 waiter 发现下面两种情况的其中之一，它就会把这个 Mutex 转换成正常模式： 此 waiter 已经是队列中的最后一个 waiter 了，没有其它的等待锁的 goroutine 了； ","date":"2024-01-12","objectID":"/mutex/:4:4","tags":["Go"],"title":"mutex用法","uri":"/mutex/"},{"categories":["Go"],"content":"常见的 4 种错误场景 lock/unlock不是成对出现 Lock/Unlock 没有成对出现，就意味着会出现死锁的情况，或者是因为 Unlock 一个未加锁的 Mutex 而导致 panic Copy已使用的Mutex vet 工具，把检查写在 Makefile 文件中，在持续集成的时候跑一跑，这样可以及时发现问题，及时修复。我们可以使用 go vet 检查这个 Go文件 重入 当一个线程获取锁时，如果没有其它线程拥有这个锁，那么，这个线程就成功获取到这个锁。之后，如果其它线程再请求这个锁，就会处于阻塞等待的状态。但是，如果拥有这把锁的线程再请求这把锁的话，不会阻塞，而是成功返回，所以叫可重入锁（有时候也叫做递归锁）。只要你拥有这把锁，你可以可着劲儿地调用，比如通过递归实现一些算法，调用者不会阻塞或者死锁 ","date":"2024-01-12","objectID":"/mutex/:5:0","tags":["Go"],"title":"mutex用法","uri":"/mutex/"},{"categories":["Go"],"content":"Mutex 不是可重入的锁 实现重入锁的方案： 方案一：gorotine id 第一步：我们先获取到 TLS 对象； 第二步：再从 TLS 中获取 goroutine 结构的 g 指针； 第三步：再从 g 指针中取出 goroutine id 推荐一个常用的库：petermattis/goid // RecursiveMutex 包装一个Mutex,实现可重入 type RecursiveMutex struct { sync.Mutex owner int64 // 当前持有锁的goroutine id recursion int32 // 这个goroutine 重入的次数 } func (m *RecursiveMutex) Lock() { gid := goid.Get() // 如果当前持有锁的goroutine就是这次调用的goroutine,说明是重入 if atomic.LoadInt64(\u0026m.owner) == gid { m.recursion++ return } m.Mutex.Lock() // 获得锁的goroutine第一次调用，记录下它的goroutine id,调用次数加1 atomic.StoreInt64(\u0026m.owner, gid) m.recursion = 1 } func (m *RecursiveMutex) Unlock() { gid := goid.Get() // 非持有锁的goroutine尝试释放锁，错误的使用 if atomic.LoadInt64(\u0026m.owner) != gid { panic(fmt.Sprintf(\"wrong the owner(%d): %d!\", m.owner, gid)) } // 调用次数减1 m.recursion-- if m.recursion != 0 { // 如果这个goroutine还没有完全释放，则直接返回 return } // 此goroutine最后一次调用，需要释放锁 atomic.StoreInt64(\u0026m.owner, -1) m.Mutex.Unlock() } 方案二：token // Token方式的递归锁 type TokenRecursiveMutex struct { sync.Mutex token int64 recursion int32 } // 请求锁，需要传入token func (m *TokenRecursiveMutex) Lock(token int64) { if atomic.LoadInt64(\u0026m.token) == token { //如果传入的token和持有锁的token一致，说明是递归调用 m.recursion++ return } m.Mutex.Lock() // 传入的token不一致，说明不是递归调用 // 抢到锁之后记录这个token atomic.StoreInt64(\u0026m.token, token) m.recursion = 1 } // 释放锁 func (m *TokenRecursiveMutex) Unlock(token int64) { if atomic.LoadInt64(\u0026m.token) != token { // 释放其它token持有的锁 panic(fmt.Sprintf(\"wrong the owner(%d): %d!\", m.token, token)) } m.recursion-- // 当前持有这个锁的token释放锁 if m.recursion != 0 { // 还没有回退到最初的递归调用 return } atomic.StoreInt64(\u0026m.token, 0) // 没有递归调用了，释放锁 m.Mutex.Unlock() } 死锁 四个条件： 互斥 持有和等待 不可剥夺 环路等待 ","date":"2024-01-12","objectID":"/mutex/:5:1","tags":["Go"],"title":"mutex用法","uri":"/mutex/"},{"categories":["Go"],"content":"功能扩展 ","date":"2024-01-12","objectID":"/mutex/:6:0","tags":["Go"],"title":"mutex用法","uri":"/mutex/"},{"categories":["Go"],"content":"TryLock 当一个 goroutine 调用这个TryLock 方法请求锁的时候，如果这把锁没有被其他 goroutine 所持有，那么，这个goroutine 就持有了这把锁，并返回 true；如果这把锁已经被其他 goroutine 所持有，或者是正在准备交给某个被唤醒的 goroutine，那么，这个请求锁的 goroutine 就直接返回false，不会阻塞在方法调用上 func (m *Mutex) TryLock() bool { // 已加锁/饥饿状态返回false old := m.state if old\u0026(mutexLocked|mutexStarving) != 0 { return false } // 竞争失败则返回false，否则标记锁状态 if !atomic.CompareAndSwapInt32(\u0026m.state, old, old|mutexLocked) { return false } if race.Enabled { race.Acquire(unsafe.Pointer(m)) } return true } ","date":"2024-01-12","objectID":"/mutex/:6:1","tags":["Go"],"title":"mutex用法","uri":"/mutex/"},{"categories":["Go"],"content":"获取等待者的数量等指标 const ( mutexLocked = 1 \u003c\u003c iota // mutex is locked mutexWoken mutexStarving mutexWaiterShift = iota ) type Mutex struct { sync.Mutex } func (m *Mutex) Count() int { // 获取state字段的值 v := atomic.LoadInt32((*int32)(unsafe.Pointer(\u0026m.Mutex))) v = v \u003e\u003e mutexWaiterShift //得到等待者的数值 v = v + (v \u0026 mutexLocked) //再加上锁持有者的数量，0或者1 return int(v) } state 这个字段的第一位是用来标记锁是否被持有，第二位用来标记是否已经唤醒了一个等待者，第三位标记锁是否处于饥饿状态，通过分析这个 state 字段我们就可以得到这些状态信息。我们可以为这些状态提供查询的方法，这样就可以实时地知道锁的状态了 // 锁是否被持有 func (m *Mutex) IsLocked() bool { state := atomic.LoadInt32((*int32)(unsafe.Pointer(\u0026m.Mutex))) return state\u0026mutexLocked == mutexLocked } // 是否有等待者被唤醒 func (m *Mutex) IsWoken() bool { state := atomic.LoadInt32((*int32)(unsafe.Pointer(\u0026m.Mutex))) return state\u0026mutexWoken == mutexWoken } // 锁是否处于饥饿状态 func (m *Mutex) IsStarving() bool { state := atomic.LoadInt32((*int32)(unsafe.Pointer(\u0026m.Mutex))) return state\u0026mutexStarving == mutexStarving } ","date":"2024-01-12","objectID":"/mutex/:6:2","tags":["Go"],"title":"mutex用法","uri":"/mutex/"},{"categories":["Go"],"content":"实现一个线程安全的队列 队列，我们可以通过 Slice 来实现，但是通过 Slice 实现的队列不是线程安全的，出队（Dequeue）和入队（Enqueue）会有 data race 的问题。这个时候，Mutex 就要隆重出场了，通过它，我们可以在出队和入队的时候加上锁的保护 type SliceQueue struct { data []interface{} mu sync.Mutex } func NewSliceQueue(n int) (q *SliceQueue) { return \u0026SliceQueue{data: make([]interface{}, 0, n)} } // Enqueue 把值放在队尾 func (q *SliceQueue) Enqueue(v interface{}) { q.mu.Lock() q.data = append(q.data, v) q.mu.Unlock() } // Dequeue 移去队头并返回 func (q *SliceQueue) Dequeue() interface{} { q.mu.Lock() if len(q.data) == 0 { q.mu.Unlock() return nil } v := q.data[0] q.data = q.data[1:] q.mu.Unlock() return v } ","date":"2024-01-12","objectID":"/mutex/:7:0","tags":["Go"],"title":"mutex用法","uri":"/mutex/"},{"categories":["Go"],"content":"这篇文章展示了rwmutex用法","date":"2024-01-12","objectID":"/rwmutex/","tags":["Go"],"title":"rwmutex用法","uri":"/rwmutex/"},{"categories":["Go"],"content":"什么是RWMutex？ 方法： Lock/Unlock：写操作时调用的方法 RLock/RUnlock：读操作时调用的方法 RLocker：为读操作返回一个Locker接口的对象 package main import ( \"sync\" \"time\" ) type Counter struct { mu sync.RWMutex count uint64 } func (c *Counter) Incr() { c.mu.Lock() c.count++ c.mu.Unlock() } func (c *Counter) Value() uint64 { c.mu.RLock() defer c.mu.RUnlock() return c.count } func main() { var counter Counter for i := 0; i \u003c 10; i++ { go func() { for { counter.Value() time.Sleep(time.Millisecond) } }() } for { counter.Incr() time.Sleep(time.Millisecond) } } 应用场景 如果你遇到可以明确区分 reader 和 writer goroutine 的场景，且有大量的并发读、少量的并发写，并且有强烈的性能需求，你就可以考虑使用读写锁 RWMutex 替换 Mutex。 实现原理 readers-writers问题分为三类： Read-preferring Write-preferring 不指定优先级 Go 标准库中的 RWMutex 设计是 Write-preferring 方案。一个正在阻塞的 Lock 调用会排除新的 reader 请求到锁 实现 RLock/RUnlock实现 func (rw *RWMutex) RLock() { if race.Enabled { _ = rw.w.state race.Disable() } if rw.readerCount.Add(1) \u003c 0 { // A writer is pending, wait for it. runtime_SemacquireRWMutexR(\u0026rw.readerSem, false, 0) } if race.Enabled { race.Enable() race.Acquire(unsafe.Pointer(\u0026rw.readerSem)) } } .... func (rw *RWMutex) RUnlock() { if race.Enabled { _ = rw.w.state race.ReleaseMerge(unsafe.Pointer(\u0026rw.writerSem)) race.Disable() } if r := rw.readerCount.Add(-1); r \u003c 0 { // 有等待的 writer rw.rUnlockSlow(r) } if race.Enabled { race.Enable() } } func (rw *RWMutex) rUnlockSlow(r int32) { if r+1 == 0 || r+1 == -rwmutexMaxReaders { race.Enable() fatal(\"sync: RUnlock of unlocked RWMutex\") } if rw.readerWait.Add(-1) == 0 { //最后一个 reader,writer有机会获取锁了 runtime_Semrelease(\u0026rw.writerSem, false, 1) } } Lock func (rw *RWMutex) Lock() { if race.Enabled { _ = rw.w.state race.Disable() } // 首先解决其他 writer的竞争问题 rw.w.Lock() // 反转 readerCount,告诉 reader有 writer竞争锁 r := rw.readerCount.Add(-rwmutexMaxReaders) + rwmutexMaxReaders // 如果当前 reader持有锁，那么需要等待 if r != 0 \u0026\u0026 rw.readerWait.Add(r) != 0 { runtime_SemacquireRWMutex(\u0026rw.writerSem, false, 0) } if race.Enabled { race.Enable() race.Acquire(unsafe.Pointer(\u0026rw.readerSem)) race.Acquire(unsafe.Pointer(\u0026rw.writerSem)) } } Unlock func (rw *RWMutex) Unlock() { if race.Enabled { _ = rw.w.state race.Release(unsafe.Pointer(\u0026rw.readerSem)) race.Disable() } // 告诉 reader没有活跃的 writer了 r := rw.readerCount.Add(rwmutexMaxReaders) if r \u003e= rwmutexMaxReaders { race.Enable() fatal(\"sync: Unlock of unlocked RWMutex\") } // 唤醒阻塞的 reader们 for i := 0; i \u003c int(r); i++ { runtime_Semrelease(\u0026rw.readerSem, false, 0) } // 释放内部的互斥锁 rw.w.Unlock() if race.Enabled { race.Enable() } } 3 个踩坑点 坑点1：不可复制 坑点2：重入导致死锁 场景 1： func main() { l := \u0026sync.RWMutex{} foo(l) } func foo(l *sync.RWMutex) { fmt.Println(\"in foo\") l.Lock() bar(l) l.Unlock() } func bar(l *sync.RWMutex) { l.Lock() fmt.Println(\"in bar\") l.Unlock() } 场景二： 有活跃 reader 的时候，writer 会等待，如果我们在 reader 的读操作时调用 writer 的写操作（它会调用 Lock 方法），那么，这个 reader和 writer 就会形成互相依赖的死锁状态 场景三： writer 依赖活跃的 reader -\u003e 活跃的 reader 依赖新来的 reader -\u003e 新来的 reader依赖 writer func main() { var mu sync.RWMutex go func() { time.Sleep(100 * time.Millisecond) mu.Lock() fmt.Println(\"Lock\") time.Sleep(100 * time.Millisecond) mu.Unlock() fmt.Println(\"Unlock\") }() go func() { factorial(\u0026mu, 10) }() select {} } func factorial(mu *sync.RWMutex, n int) int { if n \u003c 1 { return 0 } fmt.Println(\"Rlock\") mu.RLock() defer func() { fmt.Println(\"RUnlock\") mu.RUnlock() }() time.Sleep(100 * time.Millisecond) return factorial(mu, n-1) * n } 坑点3：释放未加锁的RWMutex ","date":"2024-01-12","objectID":"/rwmutex/:0:1","tags":["Go"],"title":"rwmutex用法","uri":"/rwmutex/"},{"categories":["Go"],"content":"这篇文章展示了waitgroup用法","date":"2024-01-12","objectID":"/waitgroup/","tags":["Go"],"title":"waitgroup用法","uri":"/waitgroup/"},{"categories":["Go"],"content":"基本用法 once常常用来初始化单例资源，或者并发访问只需初始化一次的共享资源，或者在测试的时候初始化一次测试资源 ","date":"2024-01-12","objectID":"/waitgroup/:0:1","tags":["Go"],"title":"waitgroup用法","uri":"/waitgroup/"},{"categories":["Go"],"content":"实现 Add方法逻辑： Add 方法主要操作的是 state 的计数部分。你可以为计数值增加一个 delta 值，内部通过原子操作把这个值加到计数值上。需要注意的是，这个 delta 也可以是个负数，相当于为计数值减去一个值，Done 方法内部其实就是通过Add(-1) 实现的。 Wait方法逻辑： 不断检查 state 的值。如果其中的计数值变为了 0，那么说明所有的任务已完成，调用者不必再等待，直接返回。如果计数值大于 0，说明此时还有任务没完成，那么调用者就变成了等待者，需要加入 waiter 队列，并且阻塞住自己。 ","date":"2024-01-12","objectID":"/waitgroup/:0:2","tags":["Go"],"title":"waitgroup用法","uri":"/waitgroup/"},{"categories":["Go"],"content":"常见问题 计数器设置为负数 解决方案： a.调用add的时候传递一个负数 b.调用done方法的次数过多，超过了waitGroup的计数值 使用 WaitGroup 的正确姿势是，预先确定好 WaitGroup 的计数值，然后调用相同次数的 Done 完成相应的任务 不期望的add时机 解决方案：等所有的 Add 方法调用之后再调用 Wait 前一个wait还没结束就重用waitGroup 解决方案：WaitGroup 虽然可以重用，但是是有一个前提的，那就是必须等到上一轮的Wait 完成之后，才能重用 WaitGroup 执行下一轮的 Add/Wait，如果你在 Wait 还没执行完的时候就调用下一轮 Add 方法，就有可能出现 panic ","date":"2024-01-12","objectID":"/waitgroup/:0:3","tags":["Go"],"title":"waitgroup用法","uri":"/waitgroup/"},{"categories":["Go"],"content":"基本用法 package main import ( \"fmt\" \"sync\" \"time\" ) type Counter struct { mu sync.RWMutex count uint64 } func (c *Counter) Incr() { c.mu.Lock() c.count++ c.mu.Unlock() } func (c *Counter) Count() uint64 { c.mu.RLock() defer c.mu.RUnlock() return c.count } func worker(c *Counter, wg *sync.WaitGroup) { defer wg.Done() time.Sleep(time.Second) c.Incr() } func main() { var counter Counter var wg sync.WaitGroup wg.Add(10) for i := 0; i \u003c 10; i++ { go worker(\u0026counter, \u0026wg) } wg.Wait() fmt.Println(counter.Count()) } ","date":"2024-01-12","objectID":"/waitgroup/:0:4","tags":["Go"],"title":"waitgroup用法","uri":"/waitgroup/"},{"categories":["Go"],"content":"实现 type WaitGroup struct { noCopy noCopy // 高 32 位为计数值，低 32 位是 waiter的计数 state atomic.Uint64 sema uint32 } ","date":"2024-01-12","objectID":"/waitgroup/:0:5","tags":["Go"],"title":"waitgroup用法","uri":"/waitgroup/"},{"categories":["Design"],"content":"这篇文章展示了软件设计原则基本知识.","date":"2024-01-12","objectID":"/mod/","tags":["Design"],"title":"软件设计原则","uri":"/mod/"},{"categories":["Design"],"content":"糟糕的设计 ","date":"2024-01-12","objectID":"/mod/:1:0","tags":["Design"],"title":"软件设计原则","uri":"/mod/"},{"categories":["Design"],"content":"僵化性 软件代码之间耦合严重,难以改动,任何微小的改动都会引起更大范围的改动。 ","date":"2024-01-12","objectID":"/mod/:1:1","tags":["Design"],"title":"软件设计原则","uri":"/mod/"},{"categories":["Design"],"content":"脆弱性 微小的改动容易引起莫名其妙的崩溃或者 bug,出现 bug 的地方看似与改动的地方毫无关联,或者软件进行了一个看似简单的改动,重新启动,然后就莫名其妙地崩溃了。 ","date":"2024-01-12","objectID":"/mod/:1:2","tags":["Design"],"title":"软件设计原则","uri":"/mod/"},{"categories":["Design"],"content":"牢固性 软件无法进行快速、有效地拆分。 ","date":"2024-01-12","objectID":"/mod/:1:3","tags":["Design"],"title":"软件设计原则","uri":"/mod/"},{"categories":["Design"],"content":"粘滞性 ","date":"2024-01-12","objectID":"/mod/:1:4","tags":["Design"],"title":"软件设计原则","uri":"/mod/"},{"categories":["Design"],"content":"晦涩性 ","date":"2024-01-12","objectID":"/mod/:1:5","tags":["Design"],"title":"软件设计原则","uri":"/mod/"},{"categories":["Design"],"content":"开闭原则 软件实体(模块、类、函数等等)应该对扩展是开放的,对修改是关闭的。 对扩展是开放的,意味着软件实体的行为是可扩展的,当需求变更的时候,可以对模块进行扩展,使其满足需求变更的要求。 对修改是关闭的,意味着当对软件实体进行扩展的时候,不需要改动当前的软件实体;不需要修改代码;对于已经完成的类文件不需要重新编辑;对于已经编译打包好的模块,不需要再重新编译。 ","date":"2024-01-12","objectID":"/mod/:2:0","tags":["Design"],"title":"软件设计原则","uri":"/mod/"},{"categories":["Design"],"content":"一个违反开闭原则的例子 当我们在代码中看到 else 或者 switch/case 关键字的时候,基本可以判断违反开闭原则了。 ","date":"2024-01-12","objectID":"/mod/:2:1","tags":["Design"],"title":"软件设计原则","uri":"/mod/"},{"categories":["Design"],"content":"使用策略模式实现开闭原则 策略模式是一种行为模式,多个策略实现同一个策略接口 ","date":"2024-01-12","objectID":"/mod/:2:2","tags":["Design"],"title":"软件设计原则","uri":"/mod/"},{"categories":["Design"],"content":"使用适配器模式实现开闭原则 ","date":"2024-01-12","objectID":"/mod/:2:3","tags":["Design"],"title":"软件设计原则","uri":"/mod/"},{"categories":["Design"],"content":"使用观察者模式实现开闭原则 观察者模式是一种行为模式,解决一对多的对象依赖关系,将被观察者对象的行为通知到多个观察者,也就是监听者对象。 ","date":"2024-01-12","objectID":"/mod/:2:4","tags":["Design"],"title":"软件设计原则","uri":"/mod/"},{"categories":["Design"],"content":"使用模板方法模式实现开闭原则 ","date":"2024-01-12","objectID":"/mod/:2:5","tags":["Design"],"title":"软件设计原则","uri":"/mod/"},{"categories":["Mysql"],"content":"这篇文章展示了Mysql架构基本知识.","date":"2024-01-11","objectID":"/mysql_prepare/","tags":["Mysql"],"title":"Mysql架构","uri":"/mysql_prepare/"},{"categories":["Mysql"],"content":"数据库架构与 SQL执行过程 –\u003e连接器–\u003e语法分析器–\u003e语义分析与优化器–\u003e执行引擎 应用程序需要对数据库连接进行管理,一方面通过连接池对连接进行管理,空闲连接会被及时释放;另一方面微服务架构可以大大减少数据库连接 语法分析器生成的抽象语法树并不仅仅可以用来做语法校验,它也是下一步处理的基础。语义分析与优化器会对抽象语法树进一步做语义优化 连接器收到 SQL 以后,会将 SQL 交给语法分析器进行处理,语法分析器工作比较简单机械,就是根据 SQL 语法规则生成对应的抽象语法树 语义分析与优化器最后会输出一个执行计划,由执行引擎完成数据查询或者更新。 ","date":"2024-01-11","objectID":"/mysql_prepare/:0:1","tags":["Mysql"],"title":"Mysql架构","uri":"/mysql_prepare/"},{"categories":["Mysql"],"content":"使用 PrepareStatement 执行 SQL 的好处 一个是 PrepareStatement 会预先提交带占位符的 SQL 到数据库进行预处理,提前生成执行计划,当给定占位符参数,真正执行 SQL 的时候,执行引擎可以直接执行,效率更好一点。 另一个好处则更为重要,PrepareStatement 可以防止 SQL 注入攻击。 ","date":"2024-01-11","objectID":"/mysql_prepare/:0:2","tags":["Mysql"],"title":"Mysql架构","uri":"/mysql_prepare/"},{"categories":["Mysql"],"content":"数据库文件存储原理 B+ 树是一种 N 叉排序树,树的每个节点包含 N 个数据,这些数据按顺序排好,两个数据之间是一个指向子节点的指针, 而子节点的数据则在这两个数据大小之间。 一种是聚簇索引,聚簇索引的数据库记录和索引存储在一起,上面这张图就是聚簇索引的示意图,在叶子节点,索引 1 和记录行 r1 存储在一起,查找到索引就是查找到数据库记录。像 MySQL 数据库的主键就是聚簇索引,主键 ID 和所在的记录行存储在一起。MySQL 的数据库文件实际上是以主键作为中间节点,行记录作为叶子节点的一颗 B+ 树。 另一种数据库索引是非聚簇索引,非聚簇索引在叶子节点记录的就不是数据行记录,而是聚簇索引,也就是主键 通过 B+ 树在叶子节点找到非聚簇索引 a,和索引 a 在一起存储的是主键 1,再根据主键 1 通过主键(聚簇)索引就可以找到对应的记录 r1,这种通过非聚簇索引找到主键索引,再通过主键索引找到行记录的过程也被称作回表 ","date":"2024-01-11","objectID":"/mysql_prepare/:0:3","tags":["Mysql"],"title":"Mysql架构","uri":"/mysql_prepare/"},{"categories":["Mysql"],"content":"基础架构 连接器 命令： Mysql -h$ip -P$port -u$user -p 查看mysql是否是空闲状态： Show processlist 其中的Command 列显示为“Sleep”的这一行，就表示现在系统里面有一个空闲连接。 长连接和短链接： 长连接是指连接成功后，如果客户端持续有请求，则一直使用同一个连接。短连接则是指每次执行完很少的几次查询就断开连接，下次查询再重新建立一个。 查询缓存 将参数 query_cache_type 设置成 DEMAND，这样对于默认的 SQL 语句都不使用查询缓存。而对于你确定要使用查询缓存的语句，可以用 SQL_CACHE 显式指定，像下面这个语句一样： Select SQL_CACHE * from T where id = 10; Mysql8.0以上版本不在适用。 分析器 词法分析-\u003e语法分析 优化器 在表里面有多个索引的时候，决定使用哪个索引；或者在一个语句有多表关联（join）的时候，决定各个表的连接顺序。 执行器 判断是否有执行查询的权限 慢查询日志中看到一个 rows_examined 的字段，表示这个语句执行过程中扫描了多少行。这个值就是在执行器每次调用引擎获取数据行的时候累加的。 引擎扫描行数跟rows_examined 并不是完全相同的。 ","date":"2024-01-11","objectID":"/mysql_prepare/:0:4","tags":["Mysql"],"title":"Mysql架构","uri":"/mysql_prepare/"},{"categories":["Go"],"content":"这篇文章展示了使用Goroutine如何控制HTTP请求的并发量","date":"2024-01-10","objectID":"/concurrency/","tags":["Go"],"title":"使用Goroutine如何控制HTTP请求的并发量","uri":"/concurrency/"},{"categories":["Go"],"content":"场景 我们使用 go 并发调用接口发起 HTTP 请求时，只需要在 func() 前面加上 go 关键字就很容易完成了，就是因为让并发变得如此简单，所以有的时候我们就需要控制一下并发请求的数量。 现在有个需求：本地有一千万条手机号，需要调用聚合数据 手机号码归属地 接口，并记录省份、城市、区号、邮编、运营商等查询结果数据。 ","date":"2024-01-10","objectID":"/concurrency/:0:1","tags":["Go"],"title":"使用Goroutine如何控制HTTP请求的并发量","uri":"/concurrency/"},{"categories":["Go"],"content":"实现 package main import( \"fmt\" \"io/ioutil\" \"math/rand\" \"net/http\" \"net/url\" \"sync\" \"time\" ) type Limit struct { number int channel chan struct{} } // Limit struct 初始化 func New(number int) *Limit { return \u0026Limit{ number: number, channel: make(chan struct{}, number), } } // Run 方法：创建有限的 go f 函数的 goroutine func (limit *Limit) Run(f func()) { limit.channel \u003c- struct{}{} go func() { f() \u003c-limit.channel }() } // WaitGroup 对象内部有一个计数器，从0开始 // 有三个方法：Add(), Done(), Wait() 用来控制计数器的数量 var wg = sync.WaitGroup{} const ( concurrency = 5 // 控制并发量 ) func main() { start := time.Now() limit := New(concurrency) // New Limit 控制并发量 // 接口请求URL apiUrl := \"http://apis.juhe.cn/mobile/get\" // 不要使用接口地址测试 //max := int(math.Pow10(8)) // 模拟一千万数据 max := 5 // 先测试5次吧 // 初始化参数 param := url.Values{} param.Set(\"key\", \"您申请的KEY\") // 接口请求Key for i := 0; i \u003c max; i++ { wg.Add(1) value := i goFunc := func() { fmt.Printf(\"start func: %dn\", value) // 配置请求参数,方法内部已处理urlencode问题,中文参数可以直接传参 phone := RandMobile() param.Set(\"phone\", phone) // 需要查询的手机号码或手机号码前7位 // 发送请求 data, err := Get(apiUrl, param) if err != nil { fmt.Println(err) return } // 其它逻辑代码... fmt.Println(\"phone: \", phone, string(data)) wg.Done() } limit.Run(goFunc) } // 阻塞代码防止退出 wg.Wait() fmt.Printf(\"耗时: %fs\", time.Now().Sub(start).Seconds()) } // Get 方式发起网络请求 func Get(apiURL string, params url.Values) (rs []byte, err error) { var Url *url.URL Url, err = url.Parse(apiURL) if err != nil { fmt.Printf(\"解析url错误:rn%v\", err) return nil, err } //如果参数中有中文参数,这个方法会进行URLEncode Url.RawQuery = params.Encode() resp, err := http.Get(Url.String()) if err != nil { fmt.Println(\"err:\", err) return nil, err } defer resp.Body.Close() return ioutil.ReadAll(resp.Body) } var MobilePrefix = [...]string{\"130\", \"131\", \"132\", \"133\", \"134\", \"135\", \"136\", \"137\", \"138\", \"139\", \"145\", \"147\", \"150\", \"151\", \"152\", \"153\", \"155\", \"156\", \"157\", \"158\", \"159\", \"170\", \"176\", \"177\", \"178\", \"180\", \"181\", \"182\", \"183\", \"184\", \"185\", \"186\", \"187\", \"188\", \"189\"} // GeneratorPhone 生成手机号码 func RandMobile() string { return MobilePrefix[RandInt(0, len(MobilePrefix))] + fmt.Sprintf(\"%0*d\", 8, RandInt(0, 100000000)) } // 指定范围随机 int func RandInt(min, max int) int { rand.Seed(time.Now().UnixNano()) return min + rand.Intn(max-min) } ","date":"2024-01-10","objectID":"/concurrency/:0:2","tags":["Go"],"title":"使用Goroutine如何控制HTTP请求的并发量","uri":"/concurrency/"}]